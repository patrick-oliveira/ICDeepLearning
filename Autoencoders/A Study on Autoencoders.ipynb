{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___To dos:___\n",
    "\n",
    "- Program a function to visualize data, and to plot comparisons between the input data and the network's output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from structure_utils import *\n",
    "from train_utils import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch import nn\n",
    "\n",
    "ngpu = 1\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__General Structure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.decoder(self.encoder(X))\n",
    "    \n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Autoencoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(784, 128, 'relu'),\n",
    "                             LinearBlock(128, 64, 'relu'),\n",
    "                             LinearBlock(64, 32, 'relu'))\n",
    "    \n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(32, 64, 'relu'),\n",
    "                             LinearBlock(64, 128, 'relu'),\n",
    "                             LinearBlock(128, 784, 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: 18048\n",
      "Val Data Shape: 3008\n"
     ]
    }
   ],
   "source": [
    "# model, dataloaders, dataset_size, criterion, optimizer, scheduler = None, num_epochs = 10\n",
    "model = BasicAutoencoder().to(device)\n",
    "dataloaders, dataset_size = load_FashionMNIST(BATCH_SIZE = 64, size = 0.3)\n",
    "# dataloaders, dataset_size = load_cifar(BATCH_SIZE = 64, size = 0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    Stage       Loss  \n",
      "\n",
      "1/100    Training    0.17  \n",
      "         Validation  0.10  \n",
      "2/100    Training    0.09  \n",
      "         Validation  0.09  \n",
      "3/100    Training    0.08  \n",
      "         Validation  0.08  \n",
      "4/100    Training    0.08  \n",
      "         Validation  0.08  \n",
      "5/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "6/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "7/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "8/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "9/100    Training    0.06  \n",
      "         Validation  0.07  \n",
      "10/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "11/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "12/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "13/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "14/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "15/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "16/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "17/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "18/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "19/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "20/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "21/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "22/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "23/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "24/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "25/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "26/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "27/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "28/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "29/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "30/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "31/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "32/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "33/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "34/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "35/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "36/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "37/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "38/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "39/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "40/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "41/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "42/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "43/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "44/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "45/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "46/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "47/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "48/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "49/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "50/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "51/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "52/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "53/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "54/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "55/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "56/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "57/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "58/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "59/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "60/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "61/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "62/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "63/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "64/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "65/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "66/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "67/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "68/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "69/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "70/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "71/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "72/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "73/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "74/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "75/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "76/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "77/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "78/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "79/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "80/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "81/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "82/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "83/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "84/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "85/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "86/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "87/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "88/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "89/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "90/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "91/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "92/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "93/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "94/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "95/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "96/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "97/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "98/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "99/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "100/100  Training    0.06  \n",
      "         Validation  0.06  \n",
      "Training complete in 7m 25s\n",
      "Best Validation Loss: 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs)\n",
    "# You need to verify why the validation error is smaller than the training error.\n",
    "# Test again, you changed the LinearBlock class.\n",
    "# Also:\n",
    "# Automatize the proccess of plotting measures of the network's training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convolutional Autoencoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(ConvPoolBlock(in_size = 1, out_size = 16, kernel = 3, pad_size = 1, pool_kernel = 2, act_function = 'relu'),\n",
    "                             ConvPoolBlock(in_size = 16, out_size = 8, kernel = 3, pad_size = 1, pool_kernel = 2, act_function = 'relu'))\n",
    "\n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(ConvUpsampleBlock(in_size = 8, out_size = 8, kernel = 3, pad_size = 1, scale_factor = 2, act_function = 'relu'),\n",
    "                             ConvUpsampleBlock(in_size = 8, out_size = 16, kernel = 3, pad_size = 1, scale_factor = 2, act_function = 'relu'),\n",
    "                             ConvBlock(in_size = 16, out_size = 1, kernel = 3, pad_size = 1, act_function = 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: 18048\n",
      "Val Data Shape: 3008\n"
     ]
    }
   ],
   "source": [
    "model = ConvolutionalAutoencoder().to(device)\n",
    "dataloaders, dataset_size = load_FashionMNIST(BATCH_SIZE = 64, size = 0.3)\n",
    "# dataloaders, dataset_size = load_cifar(BATCH_SIZE = 64, size = 0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    Stage       Loss  \n",
      "\n",
      "1/100    Training    0.16  \n",
      "         Validation  0.11  \n",
      "2/100    Training    0.09  \n",
      "         Validation  0.08  \n",
      "3/100    Training    0.08  \n",
      "         Validation  0.07  \n",
      "4/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "5/100    Training    0.06  \n",
      "         Validation  0.06  \n",
      "6/100    Training    0.06  \n",
      "         Validation  0.06  \n",
      "7/100    Training    0.06  \n",
      "         Validation  0.05  \n",
      "8/100    Training    0.05  \n",
      "         Validation  0.05  \n",
      "9/100    Training    0.05  \n",
      "         Validation  0.05  \n",
      "10/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "11/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "12/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "13/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "14/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "15/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "16/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "17/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "18/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "19/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "20/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "21/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "22/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "23/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "24/100   Training    0.05  \n",
      "         Validation  0.05  \n",
      "25/100   Training    0.04  \n",
      "         Validation  0.05  \n",
      "26/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "27/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "28/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "29/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "30/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "31/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "32/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "33/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "34/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "35/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "36/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "37/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "38/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "39/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "40/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "41/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "42/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "43/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "44/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "45/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "46/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "47/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "48/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "49/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "50/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "51/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "52/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "53/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "54/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "55/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "56/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "57/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "58/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "59/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "60/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "61/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "62/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "63/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "64/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "65/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "66/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "67/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "68/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "69/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "70/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "71/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "72/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "73/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "74/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "75/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "76/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "77/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "78/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "79/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "80/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "81/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "82/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "83/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "84/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "85/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "86/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "87/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "88/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "89/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "90/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "91/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "92/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "93/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "94/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "95/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "96/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "97/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "98/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "99/100   Training    0.04  \n",
      "         Validation  0.04  \n",
      "100/100  Training    0.04  \n",
      "         Validation  0.04  \n",
      "Training complete in 9m 18s\n",
      "Best Validation Loss: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, view = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### __Sparse Autoencoders__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparse Autoencoder: L1 Regularization__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class L1SparseAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(784, 128, 'relu'),\n",
    "                             LinearBlock(128, 64, 'relu'),\n",
    "                             LinearBlock(64, 32, 'relu'))\n",
    "    \n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(32, 64, 'relu'),\n",
    "                             LinearBlock(64, 128, 'relu'),\n",
    "                             LinearBlock(128, 784, 'tanh'))\n",
    "    \n",
    "    def L1Loss(self, X: torch.Tensor) -> torch.Tensor:\n",
    "        loss = 0\n",
    "#         Y = X\n",
    "#         for component in self.encoder.children():\n",
    "#             Y = component(Y)\n",
    "#             loss += torch.mean(torch.abs(Y))\n",
    "        with torch.no_grad():\n",
    "            code = self.encoder(X)\n",
    "            loss += torch.mean(torch.abs(code))\n",
    "            loss += torch.mean(torch.abs(self.decoder(code)))\n",
    "        return loss\n",
    "    \n",
    "    # This can be generalized\n",
    "    def penalty(self, X: torch.Tensor, coefficient: float = 1e-3) -> torch.Tensor:\n",
    "        '''\n",
    "        Inputs\n",
    "        X: (batch_size, 1, input_dim)\n",
    "        \n",
    "        Outputs\n",
    "        loss: a single - tensor, autograd enabled - value.\n",
    "        '''\n",
    "        return coefficient*self.L1Loss(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: 18048\n",
      "Val Data Shape: 3008\n"
     ]
    }
   ],
   "source": [
    "model = L1SparseAutoencoder().to(device)\n",
    "dataloaders, dataset_size = load_FashionMNIST(BATCH_SIZE = 64, size = 0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "num_epochs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    Stage       Loss  \n",
      "\n",
      "1/100    Training    0.17  \n",
      "         Validation  0.10  \n",
      "2/100    Training    0.09  \n",
      "         Validation  0.09  \n",
      "3/100    Training    0.08  \n",
      "         Validation  0.08  \n",
      "4/100    Training    0.08  \n",
      "         Validation  0.08  \n",
      "5/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "6/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "7/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "8/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "9/100    Training    0.07  \n",
      "         Validation  0.07  \n",
      "10/100   Training    0.07  \n",
      "         Validation  0.07  \n",
      "11/100   Training    0.06  \n",
      "         Validation  0.07  \n",
      "12/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "13/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "14/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "15/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "16/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "17/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "18/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "19/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "20/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "21/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "22/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "23/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "24/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "25/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "26/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "27/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "28/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "29/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "30/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "31/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "32/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "33/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "34/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "35/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "36/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "37/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "38/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "39/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "40/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "41/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "42/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "43/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "44/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "45/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "46/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "47/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "48/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "49/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "50/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "51/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "52/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "53/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "54/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "55/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "56/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "57/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "58/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "59/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "60/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "61/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "62/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "63/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "64/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "65/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "66/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "67/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "68/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "69/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "70/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "71/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "72/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "73/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "74/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "75/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "76/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "77/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "78/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "79/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "80/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "81/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "82/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "83/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "84/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "85/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "86/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "87/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "88/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "89/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "90/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "91/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "92/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "93/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "94/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "95/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "96/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "97/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "98/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "99/100   Training    0.06  \n",
      "         Validation  0.06  \n",
      "100/100  Training    0.06  \n",
      "         Validation  0.06  \n",
      "Training complete in 7m 34s\n",
      "Best Validation Loss: 0.06\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, view = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relational Autoencoder\n",
    "***\n",
    "\n",
    "Relational Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class product(Relation):\n",
    "    def function(self, inputs: torch.tensor, *args, **kwargs) -> torch.float:\n",
    "        value = torch.matmul(inputs, inputs.transpose(1, 2)).reshape(inputs.shape[0])\n",
    "        return (value - torch.mean(value))/(torch.std(value))\n",
    "    \n",
    "class productConv(Relation):\n",
    "    def function(self, inputs: torch.tensor, *args, **kwargs) -> torch.float:\n",
    "        inputs = inputs.view(inputs.shape[0], 1, -1)\n",
    "        value = torch.matmul(inputs, inputs.transpose(1, 2)).reshape(inputs.shape[0])\n",
    "        return (value - torch.mean(value))/(torch.std(value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: 18176\n",
      "Val Data Shape: 3072\n"
     ]
    }
   ],
   "source": [
    "model = ConvolutionalAutoencoder().to(device)\n",
    "dataloaders, dataset_size = load_FashionMNIST(BATCH_SIZE = 256, size = 0.3)\n",
    "# dataloaders, dataset_size = load_cifar(BATCH_SIZE = 256, size = 0.3)\n",
    "criterion = RelationalLoss(nn.MSELoss(), productConv(), 0.15)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-2, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 15, gamma = 0.5)\n",
    "\n",
    "num_epochs = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    Stage       Loss  \n",
      "\n",
      "1/50     Training    0.19  \n",
      "         Validation  0.13  \n",
      "2/50     Training    0.10  \n",
      "         Validation  0.09  \n",
      "3/50     Training    0.08  \n",
      "         Validation  0.08  \n",
      "4/50     Training    0.07  \n",
      "         Validation  0.07  \n",
      "5/50     Training    0.07  \n",
      "         Validation  0.06  \n",
      "6/50     Training    0.06  \n",
      "         Validation  0.06  \n",
      "7/50     Training    0.06  \n",
      "         Validation  0.06  \n",
      "8/50     Training    0.06  \n",
      "         Validation  0.06  \n",
      "9/50     Training    0.06  \n",
      "         Validation  0.06  \n",
      "10/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "11/50    Training    0.05  \n",
      "         Validation  0.06  \n",
      "12/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "13/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "14/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "15/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "16/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "17/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "18/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "19/50    Training    0.05  \n",
      "         Validation  0.05  \n",
      "20/50    Training    0.05  \n",
      "         Validation  0.04  \n",
      "21/50    Training    0.05  \n",
      "         Validation  0.04  \n",
      "22/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "23/50    Training    0.04  \n",
      "         Validation  0.05  \n",
      "24/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "25/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "26/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "27/50    Training    0.04  \n",
      "         Validation  0.05  \n",
      "28/50    Training    0.04  \n",
      "         Validation  0.05  \n",
      "29/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "30/50    Training    0.04  \n",
      "         Validation  0.05  \n",
      "31/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "32/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "33/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "34/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "35/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "36/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "37/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "38/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "39/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "40/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "41/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "42/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "43/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "44/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "45/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "46/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "47/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "48/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "49/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "50/50    Training    0.04  \n",
      "         Validation  0.04  \n",
      "Training complete in 3m 52s\n",
      "Best Validation Loss: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, view = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
