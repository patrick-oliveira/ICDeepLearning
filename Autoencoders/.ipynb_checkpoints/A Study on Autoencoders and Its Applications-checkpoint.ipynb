{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___To dos:___\n",
    "\n",
    "- Program a function to visualize data, and to plot comparisons between the input data and the network's output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Imports_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data_utils import *\n",
    "from structure_utils import *\n",
    "from train_utils import *\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.optim as optim\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__General Structure__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = self.build_encoder()\n",
    "        self.decoder = self.build_decoder()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.decoder(self.encoder(X))\n",
    "    \n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        raise NotImplementedError()\n",
    "    \n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Basic Autoencoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BasicAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(784, 128, 'relu'),\n",
    "                             LinearBlock(128, 64, 'relu'),\n",
    "                             LinearBlock(64, 32, 'relu'))\n",
    "    \n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(LinearBlock(32, 64, 'relu'),\n",
    "                             LinearBlock(64, 128, 'relu'),\n",
    "                             LinearBlock(128, 784, 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Train Data Shape: 15040\n",
      "Val Data Shape: 3008\n"
     ]
    }
   ],
   "source": [
    "# model, dataloaders, dataset_size, criterion, optimizer, scheduler = None, num_epochs = 10\n",
    "model = BasicAutoencoder()\n",
    "# dataloaders, dataset_size = load_mnist(BATCH_SIZE = 64, size = 0.3)\n",
    "dataloaders, dataset_size = load_cifar(BATCH_SIZE = 64, size = 0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs)\n",
    "# You need to verify why the validation error is smaller than the training error.\n",
    "# Test again, you changed the LinearBlock class.\n",
    "# Also:\n",
    "# Automatize the proccess of plotting measures of the network's training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Convolutional Autoencoder__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvolutionalAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(ConvPoolBlock(in_size = 1, out_size = 16, kernel = 3, pad_size = 1, pool_kernel = 2, act_function = 'relu'),\n",
    "                             ConvPoolBlock(in_size = 16, out_size = 8, kernel = 3, pad_size = 1, pool_kernel = 2, act_function = 'relu'))\n",
    "\n",
    "    def build_decoder(self, *args, **kwargs):\n",
    "        return nn.Sequential(ConvUpsampleBlock(in_size = 8, out_size = 8, kernel = 3, pad_size = 1, scale_factor = 2, act_function = 'relu'),\n",
    "                             ConvUpsampleBlock(in_size = 8, out_size = 16, kernel = 3, pad_size = 1, scale_factor = 2, act_function = 'relu'),\n",
    "                             ConvBlock(in_size = 16, out_size = 1, kernel = 3, pad_size = 1, act_function = 'tanh'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Data Shape: 18048\n",
      "Val Data Shape: 3008\n"
     ]
    }
   ],
   "source": [
    "model = ConvolutionalAutoencoder()\n",
    "dataloaders, dataset_size = load_mnist(BATCH_SIZE = 64, size = 0.3)\n",
    "# dataloaders, dataset_size = load_cifar(BATCH_SIZE = 64, size = 0.3)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "\n",
    "num_epochs = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    Stage       Loss  \n",
      "\n",
      "1/20     Training    0.41  \n",
      "         Validation  0.25  \n",
      "2/20     Training    0.19  \n",
      "         Validation  0.16  \n",
      "3/20     Training    0.13  \n",
      "         Validation  0.10  \n",
      "4/20     Training    0.09  \n",
      "         Validation  0.08  \n",
      "5/20     Training    0.08  \n",
      "         Validation  0.07  \n",
      "6/20     Training    0.07  \n",
      "         Validation  0.06  \n",
      "7/20     Training    0.06  \n",
      "         Validation  0.06  \n",
      "8/20     Training    0.06  \n",
      "         Validation  0.05  \n",
      "9/20     Training    0.05  \n",
      "         Validation  0.05  \n",
      "10/20    Training    0.05  \n",
      "         Validation  0.05  \n",
      "11/20    Training    0.05  \n",
      "         Validation  0.05  \n",
      "12/20    Training    0.05  \n",
      "         Validation  0.04  \n",
      "13/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "14/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "15/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "16/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "17/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "18/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "19/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "20/20    Training    0.04  \n",
      "         Validation  0.04  \n",
      "Training complete in 8m 38s\n",
      "Best Validation Loss: 0.04\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model, stats = train_autoencoder(model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, view = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Sparse Autoencoder: L1 Regularization__\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
