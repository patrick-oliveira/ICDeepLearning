{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from classes import *\n",
    "\n",
    "mnist_data = datasets.MNIST('data', train = True, download = True,\n",
    "                           transform = transforms.ToTensor())\n",
    "mnist_data = list(mnist_data)[:4096]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoders with convolution and deconvolution layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvBlock(1, 16, kernel_size = 3, stride = 2, padding = 1),\n",
    "            ConvBlock(16, 32, kernel_size = 3, stride = 2, padding = 1),\n",
    "            ConvBlock(32, 64, kernel_size = 7, activFunc = 'none')\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            DeconvBlock(64, 32, kernel_size = 7),\n",
    "            DeconvBlock(32, 16, kernel_size = 3, stride = 2, padding = 1, output_padding = 1),\n",
    "            DeconvBlock(16, 1,  kernel_size = 3, stride = 2, padding = 1, output_padding = 1, activFunc = 'sigmoid')\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "        X = self.decoder(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, num_epochs = 5, batch_size = 64, learning_rate = 1e-3):\n",
    "    torch.manual_seed(42)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(),\n",
    "                                 lr = learning_rate,\n",
    "                                 weight_decay = 1e-5)\n",
    "    train_loader = torch.utils.data.DataLoader(mnist_data,\n",
    "                                               batch_size = batch_size,\n",
    "                                               shuffle = True)\n",
    "    outputs = []\n",
    "    for epoch in range(num_epochs):\n",
    "        for data in train_loader:\n",
    "            img, _ = data\n",
    "            recon = model(img)\n",
    "            loss = criterion(recon, img)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "        print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "        outputs.append((epoch, img, recon),)\n",
    "    \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().\n",
    "max_epochs = 20\n",
    "outputs = train(model, num_epochs = max_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(0, max_epochs, 5):\n",
    "    plt.figure(figsize = (9, 2))\n",
    "    imgs = outputs[k][1].detach().numpy()\n",
    "    recon = outputs[k][2].detach().numpy()\n",
    "    for i, item in enumerate(imgs):\n",
    "        if i >= 9: break\n",
    "        plt.subplot(2, 9, i+1)\n",
    "        plt.imshow(item[0])\n",
    "            \n",
    "    for i, item in enumerate(recon):\n",
    "        if i >= 9: break\n",
    "        plt.subplot(2, 9, 9+i+1)\n",
    "        plt.imshow(item[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Autoencoder with upsampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A compressed representation can be great for saving and sharing any kind of data in a way that is more efficient than storing raw data. In practice, the compressed representation often holds key information about an input image and we can use it for denoising images or oher kinds of reconstruction and transformation!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from torchvision import datasets\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "transform = transforms.ToTensor()\n",
    "train_data = datasets.MNIST(root = 'data', train = True,\n",
    "                            download = True, transform = transform)\n",
    "test_data  = datasets.MNIST(root = 'data', train = False,\n",
    "                            download = True, transform = transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numWorkers = 2\n",
    "batchSize = 20\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(train_data, batch_size = batchSize,\n",
    "                                          num_workers = numWorkers)\n",
    "testLoader  = torch.utils.data.DataLoader(test_data,  batch_size = batchSize,\n",
    "                                          num_workers = numWorkers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "images, labels = iter(trainLoader).next()\n",
    "images = images.numpy()\n",
    "\n",
    "img = np.squeeze(images[0])\n",
    "\n",
    "fig = plt.figure(figsize = (5,5))\n",
    "ax = fig.add_subplot(111)\n",
    "ax.imshow(img, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvAutoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvAutoencoder, self).__init__()\n",
    "        # encoder layers #\n",
    "        self.conv1 = nn.Conv2d(1, 16, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(16, 4, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # decoder layers #\n",
    "        self.conv4 = nn.Conv2d(4, 16, 3, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(16, 1, 3, padding = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoder #\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # decoder #\n",
    "        x = F.interpolate(x, scale_factor = 2, mode = 'nearest')\n",
    "        x = F.relu(self.conv4(x))\n",
    "        \n",
    "        x = F.interpolate(x, scale_factor = 2, mode = 'nearest')\n",
    "        x = F.sigmoid(self.conv5(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = ConvAutoencoder()\n",
    "print(model)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "n_epochs = 30\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data in trainLoader:\n",
    "        images, _ = data\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(trainLoader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(testLoader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "output = model(images)\n",
    "images = images.numpy()\n",
    "\n",
    "output = output.view(batchSize, 1, 28, 28)\n",
    "output = output.detach().numpy()\n",
    "\n",
    "fig, axes = plt.subplots(nrows = 2, ncols = 10, sharex = True, sharey = True, figsize = (25, 4))\n",
    "\n",
    "for images, row in zip([images, output], axes):\n",
    "    for img, ax in zip(images, row):\n",
    "        ax.imshow(np.squeeze(img), cmap = 'gray')\n",
    "        ax.get_xaxis().set_visible(False)\n",
    "        ax.get_yaxis().set_visible(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Denoising autoencoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As I've mentioned before, autoencoders like the ones you've built so far aren't too useful in practive. However, they can be used to denoise images quite successfully just by training the network on noisy images. We can create the noisy images ourselves by adding Gaussian noise to the training images, then clipping the values to be between 0 and 1.\n",
    "\n",
    "* We'll use noisy images as input and the original, clean images as targets.\n",
    "\n",
    "* Try with different types of noises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ConvDenoiser(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvDenoiser, self).__init__()\n",
    "        \n",
    "        # encoder #\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(32, 16, 3, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(16, 8, 3, padding = 1)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        \n",
    "        # decoder #\n",
    "        self.t_conv1 = nn.ConvTranspose2d(8, 8, 3, stride = 2)\n",
    "        self.t_conv2 = nn.ConvTranspose2d(8, 16, 2, stride = 2)\n",
    "        self.t_conv3 = nn.ConvTranspose2d(16, 32, 2, stride = 2)\n",
    "        self.conv_out = nn.Conv2d(32, 1, 3, padding = 1)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encode #\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = self.pool(x)\n",
    "        \n",
    "        # decode #\n",
    "        x = F.relu(self.t_conv1(x))\n",
    "        x = F.relu(self.t_conv2(x))\n",
    "        x = F.relu(self.t_conv3(x))\n",
    "        x = F.sigmoid(self.conv_out(x))\n",
    "        \n",
    "        return x\n",
    "    \n",
    "model = ConvDenoiser()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "n_epochs = 20\n",
    "noise_factor = 0.5\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data in trainLoader:\n",
    "        images, _ = data\n",
    "        \n",
    "        noisy_imgs = images + noise_factor * torch.randn(*images.shape)\n",
    "        noisy_imgs = np.clip(noisy_imgs, 0., 1.)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(noisy_imgs)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        \n",
    "    train_loss = train_loss/len(trainLoader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, encoding_dim):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        #encoder\n",
    "        self.fc1 = nn.Linear(28*28, encoding_dim)\n",
    "        \n",
    "        #decoder\n",
    "        self.fc2 = nn.Linear(encoding_dim, 28*28)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # encoding\n",
    "        x = F.relu(self.fc1(x))\n",
    "        \n",
    "        # decoding\n",
    "        x = torch.sigmoid(self.fc2(x))\n",
    "        return x\n",
    "    \n",
    "encoding_dim = 32\n",
    "model = Autoencoder(encoding_dim)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "for epoch in range(1, n_epochs + 1):\n",
    "    train_loss = 0.0\n",
    "    \n",
    "    for data in trainLoader:\n",
    "        images, _ = data\n",
    "        images = images.view(images.size(0), -1)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()*images.size(0)\n",
    "        \n",
    "    train_loss = train_loss / len(trainLoader)\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
