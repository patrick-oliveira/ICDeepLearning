{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "from torchvision import datasets, models, transforms\n",
    "torch.manual_seed(360)\n",
    "\n",
    "import os\n",
    "from urllib import request\n",
    "from zipfile import ZipFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.datasets import make_classification # Generate a random n-class classification problem.\n",
    "from sklearn.datasets import make_regression # Generate a random regression problem.\n",
    "from sklearn.pipeline import Pipeline # Sequentially apply a list of transforms and a final estimator.\n",
    "from sklearn.preprocessing import StandardScaler # Standardize features by removing the mean and scaling to unit variance\n",
    "from sklearn.model_selection import GridSearchCV # Exhaustive search over specified parameter values for an estimator.\n",
    "from skorch import NeuralNetClassifier\n",
    "from skorch import NeuralNetRegressor\n",
    "from skorch.callbacks import EpochScoring\n",
    "from skorch.helper import predefined_split\n",
    "import pickle # Create portable serialized representations of Python objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(n_samples = 1000, n_features = 20, n_informative = 10, random_state = 0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1000, 20), (1000,), 0.5)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape, y.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClassifierModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 2)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = self.dropout(X)\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X\n",
    "    \n",
    "model = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs = 20,\n",
    "    lr = 0.1,\n",
    "    device = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6794\u001b[0m       \u001b[32m0.6150\u001b[0m        \u001b[35m0.6741\u001b[0m  0.8387\n",
      "      2        \u001b[36m0.6657\u001b[0m       \u001b[32m0.6350\u001b[0m        \u001b[35m0.6617\u001b[0m  0.0396\n",
      "      3        \u001b[36m0.6520\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6503\u001b[0m  0.0422\n",
      "      4        \u001b[36m0.6450\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6374\u001b[0m  0.0402\n",
      "      5        \u001b[36m0.6358\u001b[0m       0.7050        \u001b[35m0.6248\u001b[0m  0.0422\n",
      "      6        \u001b[36m0.6176\u001b[0m       0.7000        \u001b[35m0.6113\u001b[0m  0.0408\n",
      "      7        \u001b[36m0.6088\u001b[0m       0.7050        \u001b[35m0.5990\u001b[0m  0.0408\n",
      "      8        \u001b[36m0.5903\u001b[0m       0.7000        \u001b[35m0.5883\u001b[0m  0.0411\n",
      "      9        0.5922       0.7000        \u001b[35m0.5775\u001b[0m  0.0451\n",
      "     10        \u001b[36m0.5722\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.5632\u001b[0m  0.0409\n",
      "     11        \u001b[36m0.5711\u001b[0m       \u001b[32m0.7250\u001b[0m        \u001b[35m0.5553\u001b[0m  0.0410\n",
      "     12        \u001b[36m0.5673\u001b[0m       0.7250        \u001b[35m0.5489\u001b[0m  0.0399\n",
      "     13        \u001b[36m0.5521\u001b[0m       0.7250        \u001b[35m0.5482\u001b[0m  0.0403\n",
      "     14        0.5526       \u001b[32m0.7300\u001b[0m        \u001b[35m0.5449\u001b[0m  0.0411\n",
      "     15        \u001b[36m0.5446\u001b[0m       0.7300        \u001b[35m0.5364\u001b[0m  0.0398\n",
      "     16        \u001b[36m0.5404\u001b[0m       0.7300        \u001b[35m0.5319\u001b[0m  0.0452\n",
      "     17        0.5427       0.7250        \u001b[35m0.5275\u001b[0m  0.0405\n",
      "     18        \u001b[36m0.5385\u001b[0m       0.7300        \u001b[35m0.5261\u001b[0m  0.0396\n",
      "     19        \u001b[36m0.5252\u001b[0m       0.7300        \u001b[35m0.5217\u001b[0m  0.0398\n",
      "     20        \u001b[36m0.5098\u001b[0m       \u001b[32m0.7400\u001b[0m        \u001b[35m0.5177\u001b[0m  0.0396\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y)\n",
    "# Predictions\n",
    "# y_pred = net.predict(X[:5])\n",
    "# y_proba = net.predict_proba(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_regr, y_regr = make_regression(1000, 20, n_informative = 10, random_state = 0)\n",
    "X_regr = X_regr.astype(np.float32)\n",
    "y_regr = y_regr.astype(np.float32) / 100\n",
    "y_regr = y_regr.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RegressorModule(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units=10,\n",
    "            nonlin=F.relu,\n",
    "    ):\n",
    "        super(RegressorModule, self).__init__()\n",
    "        self.num_units = num_units\n",
    "        self.nonlin = nonlin\n",
    "\n",
    "        self.dense0 = nn.Linear(20, num_units)\n",
    "        self.nonlin = nonlin\n",
    "        self.dense1 = nn.Linear(num_units, 10)\n",
    "        self.output = nn.Linear(10, 1)\n",
    "\n",
    "    def forward(self, X, **kwargs):\n",
    "        X = self.nonlin(self.dense0(X))\n",
    "        X = F.relu(self.dense1(X))\n",
    "        X = self.output(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_regr = NeuralNetRegressor(\n",
    "    RegressorModule,\n",
    "    max_epochs = 20,\n",
    "    lr = 0.1,\n",
    "    device = 'cuda'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m4.6894\u001b[0m        \u001b[32m3.9830\u001b[0m  0.1708\n",
      "      2        \u001b[36m4.5409\u001b[0m        \u001b[32m3.6905\u001b[0m  0.0453\n",
      "      3        \u001b[36m3.6147\u001b[0m        \u001b[32m1.5435\u001b[0m  0.0625\n",
      "      4        \u001b[36m0.8586\u001b[0m        \u001b[32m0.2304\u001b[0m  0.0378\n",
      "      5        \u001b[36m0.2164\u001b[0m        0.2580  0.0312\n",
      "      6        0.3034        \u001b[32m0.0829\u001b[0m  0.0534\n",
      "      7        \u001b[36m0.1035\u001b[0m        0.2024  0.0312\n",
      "      8        0.2322        \u001b[32m0.0599\u001b[0m  0.0534\n",
      "      9        \u001b[36m0.0860\u001b[0m        0.2011  0.0469\n",
      "     10        0.1602        \u001b[32m0.0426\u001b[0m  0.0534\n",
      "     11        \u001b[36m0.0572\u001b[0m        0.0939  0.0469\n",
      "     12        0.0755        \u001b[32m0.0410\u001b[0m  0.0377\n",
      "     13        0.0625        0.1398  0.0312\n",
      "     14        0.0825        \u001b[32m0.0281\u001b[0m  0.0534\n",
      "     15        \u001b[36m0.0339\u001b[0m        0.0414  0.0469\n",
      "     16        \u001b[36m0.0269\u001b[0m        \u001b[32m0.0224\u001b[0m  0.0534\n",
      "     17        0.0286        0.0470  0.0469\n",
      "     18        0.0306        0.0240  0.0534\n",
      "     19        0.0278        0.0357  0.0469\n",
      "     20        \u001b[36m0.0218\u001b[0m        \u001b[32m0.0190\u001b[0m  0.0534\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.regressor.NeuralNetRegressor'>[initialized](\n",
       "  module_=RegressorModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=1, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net_regr.fit(X_regr, y_regr)\n",
    "# Prediction\n",
    "# y_pred = net_regr.predict(X_regr[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving the whole model\n",
    "# file_name = '/tmp/mymodel.pkl'\n",
    "# with open(file_name, 'wb') as f:\n",
    "#     pickle.dump(net, f)\n",
    "    \n",
    "# with open(file_name, 'rb') as f:\n",
    "#     new_net = pickle.load(f)\n",
    "\n",
    "# Saving only the model parameters\n",
    "# net.save_params(f_params = file_name)\n",
    "# new_net = NeuralNetClassifier(\n",
    "#     ClassifierModule,\n",
    "#     max_epochs = 20,\n",
    "#     lr = 0.1\n",
    "# ).initialize()\n",
    "# new_net.load_params(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Re-initializing module.\n",
      "Re-initializing optimizer.\n",
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.6918\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.6899\u001b[0m  0.0846\n",
      "      2        0.6925       \u001b[32m0.5100\u001b[0m        \u001b[35m0.6885\u001b[0m  0.0534\n",
      "      3        \u001b[36m0.6879\u001b[0m       \u001b[32m0.5800\u001b[0m        \u001b[35m0.6871\u001b[0m  0.0312\n",
      "      4        0.6888       \u001b[32m0.6350\u001b[0m        \u001b[35m0.6857\u001b[0m  0.0312\n",
      "      5        \u001b[36m0.6861\u001b[0m       \u001b[32m0.6500\u001b[0m        \u001b[35m0.6840\u001b[0m  0.0534\n",
      "      6        \u001b[36m0.6843\u001b[0m       0.6500        \u001b[35m0.6819\u001b[0m  0.0312\n",
      "      7        \u001b[36m0.6790\u001b[0m       \u001b[32m0.6550\u001b[0m        \u001b[35m0.6796\u001b[0m  0.0534\n",
      "      8        0.6799       0.6550        \u001b[35m0.6769\u001b[0m  0.0312\n",
      "      9        \u001b[36m0.6732\u001b[0m       \u001b[32m0.6650\u001b[0m        \u001b[35m0.6735\u001b[0m  0.0534\n",
      "     10        \u001b[36m0.6727\u001b[0m       \u001b[32m0.6700\u001b[0m        \u001b[35m0.6699\u001b[0m  0.0469\n",
      "     11        \u001b[36m0.6672\u001b[0m       \u001b[32m0.6850\u001b[0m        \u001b[35m0.6657\u001b[0m  0.0469\n",
      "     12        \u001b[36m0.6613\u001b[0m       \u001b[32m0.6900\u001b[0m        \u001b[35m0.6605\u001b[0m  0.0378\n",
      "     13        \u001b[36m0.6591\u001b[0m       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6551\u001b[0m  0.0499\n",
      "     14        \u001b[36m0.6511\u001b[0m       0.7000        \u001b[35m0.6487\u001b[0m  0.0348\n",
      "     15        \u001b[36m0.6483\u001b[0m       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6431\u001b[0m  0.0468\n",
      "     16        \u001b[36m0.6368\u001b[0m       \u001b[32m0.7150\u001b[0m        \u001b[35m0.6360\u001b[0m  0.0377\n",
      "     17        \u001b[36m0.6288\u001b[0m       0.7150        \u001b[35m0.6298\u001b[0m  0.0469\n",
      "     18        \u001b[36m0.6136\u001b[0m       0.7150        \u001b[35m0.6220\u001b[0m  0.0312\n",
      "     19        0.6161       0.7100        \u001b[35m0.6149\u001b[0m  0.0378\n",
      "     20        \u001b[36m0.6006\u001b[0m       0.7150        \u001b[35m0.6080\u001b[0m  0.0468\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scale',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('net',\n",
       "                 <class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       "))],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe = Pipeline([\n",
    "    ('scale', StandardScaler()),\n",
    "    ('net', model),\n",
    "])\n",
    "pipe.fit(X, y)\n",
    "# y_proba = pipe.predict_proba(X[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There is a scoring callback in skorch, EpochScoring, which we use for this. We have to specify which score to calculate. We have 3 choices:\n",
    "\n",
    "* Passing a string: This should be a valid sklearn metric. For a list of all existing scores, look:\n",
    "    https://scikit-learn.org/stable/modules/classes.html#sklearn-metrics-metrics\n",
    "\n",
    "* Passing None: If you implement your own .score method on your neural net, passing scoring=None will tell skorch to use that.\n",
    "\n",
    "* Passing a function or callable: If we want to define our own scoring function, we pass a function with the signature func(model, X, y) -> score, which is then used.\n",
    "\n",
    "Note that this works exactly the same as scoring in sklearn does."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    roc_auc    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ---------  ------------  -----------  ------------  ------\n",
      "      1     \u001b[36m0.6039\u001b[0m        \u001b[32m0.6872\u001b[0m       \u001b[35m0.5750\u001b[0m        \u001b[31m0.6822\u001b[0m  0.0846\n",
      "      2     \u001b[36m0.6232\u001b[0m        \u001b[32m0.6824\u001b[0m       \u001b[35m0.5800\u001b[0m        \u001b[31m0.6732\u001b[0m  0.0312\n",
      "      3     \u001b[36m0.6415\u001b[0m        \u001b[32m0.6700\u001b[0m       \u001b[35m0.6250\u001b[0m        \u001b[31m0.6651\u001b[0m  0.0221\n",
      "      4     \u001b[36m0.6612\u001b[0m        \u001b[32m0.6698\u001b[0m       \u001b[35m0.6500\u001b[0m        \u001b[31m0.6584\u001b[0m  0.0156\n",
      "      5     \u001b[36m0.6795\u001b[0m        \u001b[32m0.6544\u001b[0m       \u001b[35m0.6600\u001b[0m        \u001b[31m0.6498\u001b[0m  0.0156\n",
      "      6     \u001b[36m0.6995\u001b[0m        \u001b[32m0.6479\u001b[0m       \u001b[35m0.6850\u001b[0m        \u001b[31m0.6378\u001b[0m  0.0156\n",
      "      7     \u001b[36m0.7086\u001b[0m        \u001b[32m0.6353\u001b[0m       0.6750        \u001b[31m0.6282\u001b[0m  0.0186\n",
      "      8     \u001b[36m0.7122\u001b[0m        \u001b[32m0.6329\u001b[0m       0.6700        \u001b[31m0.6198\u001b[0m  0.0201\n",
      "      9     \u001b[36m0.7178\u001b[0m        \u001b[32m0.6135\u001b[0m       0.6800        \u001b[31m0.6085\u001b[0m  0.0201\n",
      "     10     \u001b[36m0.7270\u001b[0m        \u001b[32m0.6053\u001b[0m       \u001b[35m0.7000\u001b[0m        \u001b[31m0.6006\u001b[0m  0.0101\n",
      "     11     \u001b[36m0.7364\u001b[0m        \u001b[32m0.6050\u001b[0m       \u001b[35m0.7100\u001b[0m        \u001b[31m0.5904\u001b[0m  0.0201\n",
      "     12     \u001b[36m0.7394\u001b[0m        \u001b[32m0.5821\u001b[0m       \u001b[35m0.7200\u001b[0m        \u001b[31m0.5824\u001b[0m  0.0201\n",
      "     13     \u001b[36m0.7463\u001b[0m        \u001b[32m0.5790\u001b[0m       \u001b[35m0.7250\u001b[0m        \u001b[31m0.5753\u001b[0m  0.0201\n",
      "     14     \u001b[36m0.7598\u001b[0m        \u001b[32m0.5734\u001b[0m       0.7200        \u001b[31m0.5664\u001b[0m  0.0116\n",
      "     15     \u001b[36m0.7702\u001b[0m        \u001b[32m0.5671\u001b[0m       0.7250        \u001b[31m0.5584\u001b[0m  0.0181\n",
      "     16     \u001b[36m0.7769\u001b[0m        0.5786       0.7200        \u001b[31m0.5558\u001b[0m  0.0201\n",
      "     17     \u001b[36m0.7825\u001b[0m        \u001b[32m0.5655\u001b[0m       0.7250        \u001b[31m0.5542\u001b[0m  0.0201\n",
      "     18     \u001b[36m0.7863\u001b[0m        \u001b[32m0.5568\u001b[0m       \u001b[35m0.7300\u001b[0m        \u001b[31m0.5484\u001b[0m  0.0181\n",
      "     19     \u001b[36m0.7892\u001b[0m        \u001b[32m0.5429\u001b[0m       \u001b[35m0.7400\u001b[0m        \u001b[31m0.5403\u001b[0m  0.0201\n",
      "     20     0.7891        \u001b[32m0.5158\u001b[0m       0.7400        \u001b[31m0.5371\u001b[0m  0.0201\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auc = EpochScoring(scoring='roc_auc', lower_is_better=False)\n",
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=20,\n",
    "    lr=0.1,\n",
    "    callbacks=[auc],\n",
    ")\n",
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs = 20,\n",
    "    lr = 0.1,\n",
    "    verbose = 0,\n",
    "    optimizer__momentum = 0.9,\n",
    ")\n",
    "params = {\n",
    "    'lr': [0.05, 0.1],\n",
    "    'module__num_units': [10, 20],\n",
    "    'module__dropout': [0, 0.5],\n",
    "    'optimizer__nesterov': [False, True],\n",
    "}\n",
    "gs = GridSearchCV(net, params, refit = False, cv = 3, scoring = 'accuracy', verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.4s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.05, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=10, optimizer__nesterov=True, total=   0.4s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=False, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n",
      "[CV] lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True \n",
      "[CV]  lr=0.1, module__dropout=0.5, module__num_units=20, optimizer__nesterov=True, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  48 out of  48 | elapsed:   14.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score=nan,\n",
       "             estimator=<class 'skorch.classifier.NeuralNetClassifier'>[uninitialized](\n",
       "  module=<class '__main__.ClassifierModule'>,\n",
       "),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'lr': [0.05, 0.1], 'module__dropout': [0, 0.5],\n",
       "                         'module__num_units': [10, 20],\n",
       "                         'optimizer__nesterov': [False, True]},\n",
       "             pre_dispatch='2*n_jobs', refit=False, return_train_score=False,\n",
       "             scoring='accuracy', verbose=2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative=10, random_state=0)\n",
    "X, y = X.astype(np.float32), y.astype(np.int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Writing a custom callback"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* They should inherit from skorch.callbacks.Callback.\n",
    "* They should implement at least one of the on_-methods provided by the parent class (e.g. on_batch_begin or on_epoch_end).\n",
    "* As argument, the on_-methods first get the NeuralNet instance, and, where appropriate, the local data (e.g. the data from the current batch). The method should also have **kwargs in the signature for potentially unused arguments.\n",
    "* Optional: If you have attributes that should be reset when the model is re-initialized, those attributes should be set in the initialize method.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch.callbacks import Callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tweet(msg):\n",
    "    print('~'*60)\n",
    "    print('*tweet*', msg, '#skorch #pytorch')\n",
    "    print('~'*60)\n",
    "    \n",
    "class AccuracyTweet(Callback):\n",
    "    def __init__(self, min_accuracy):\n",
    "        self.min_accuracy = min_accuracy\n",
    "        \n",
    "    def initialize(self):\n",
    "        self.critical_epoch_ = -1\n",
    "        \n",
    "    def on_epoch_end(self, net, **kwargs):\n",
    "        if self.critical_epoch_ > -1:\n",
    "            return\n",
    "        # look at the validation accuracy of the last epoch\n",
    "        if net.history[-1, 'valid_acc'] >= self.min_accuracy:\n",
    "            self.critical_epoch_ = len(net.history)\n",
    "            \n",
    "    def on_train_end(self, net, **kwargs):\n",
    "        if self.critical_epoch_ < 0:\n",
    "            msg = 'Accuracy never reached {} :('.format(self.min_accuracy)\n",
    "        else:\n",
    "            msg = 'Accuracy reached {} at epoch {}!!!'.format(\n",
    "                    self.min_accuracy, self.critical_epoch_)\n",
    "            \n",
    "        tweet(msg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    ClassifierModule,\n",
    "    max_epochs=15,\n",
    "    lr=0.02,\n",
    "    warm_start=True,\n",
    "    callbacks=[AccuracyTweet(min_accuracy=0.7)],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7041\u001b[0m       \u001b[32m0.4900\u001b[0m        \u001b[35m0.6958\u001b[0m  0.0359\n",
      "      2        0.7087       \u001b[32m0.5100\u001b[0m        \u001b[35m0.6918\u001b[0m  0.0199\n",
      "      3        \u001b[36m0.7028\u001b[0m       \u001b[32m0.5250\u001b[0m        \u001b[35m0.6896\u001b[0m  0.0180\n",
      "      4        \u001b[36m0.6961\u001b[0m       \u001b[32m0.5550\u001b[0m        \u001b[35m0.6875\u001b[0m  0.0180\n",
      "      5        \u001b[36m0.6960\u001b[0m       0.5450        \u001b[35m0.6853\u001b[0m  0.0199\n",
      "      6        \u001b[36m0.6944\u001b[0m       \u001b[32m0.5700\u001b[0m        \u001b[35m0.6832\u001b[0m  0.0239\n",
      "      7        \u001b[36m0.6895\u001b[0m       \u001b[32m0.5750\u001b[0m        \u001b[35m0.6813\u001b[0m  0.0199\n",
      "      8        \u001b[36m0.6844\u001b[0m       \u001b[32m0.5850\u001b[0m        \u001b[35m0.6795\u001b[0m  0.0190\n",
      "      9        0.6871       \u001b[32m0.5900\u001b[0m        \u001b[35m0.6777\u001b[0m  0.0239\n",
      "     10        \u001b[36m0.6828\u001b[0m       0.5900        \u001b[35m0.6765\u001b[0m  0.0180\n",
      "     11        \u001b[36m0.6816\u001b[0m       0.5850        \u001b[35m0.6751\u001b[0m  0.0180\n",
      "     12        0.6825       0.5900        \u001b[35m0.6740\u001b[0m  0.0189\n",
      "     13        \u001b[36m0.6772\u001b[0m       \u001b[32m0.5950\u001b[0m        \u001b[35m0.6728\u001b[0m  0.0199\n",
      "     14        \u001b[36m0.6759\u001b[0m       \u001b[32m0.6050\u001b[0m        \u001b[35m0.6714\u001b[0m  0.0199\n",
      "     15        0.6773       0.6000        \u001b[35m0.6701\u001b[0m  0.0190\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*tweet* Accuracy never reached 0.7 :( #skorch #pytorch\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     46        0.6314       0.6900        \u001b[35m0.6289\u001b[0m  0.0229\n",
      "     47        0.6255       0.6950        \u001b[35m0.6275\u001b[0m  0.0180\n",
      "     48        0.6305       \u001b[32m0.7000\u001b[0m        \u001b[35m0.6265\u001b[0m  0.0180\n",
      "     49        \u001b[36m0.6204\u001b[0m       0.7000        \u001b[35m0.6247\u001b[0m  0.0170\n",
      "     50        \u001b[36m0.6187\u001b[0m       0.7000        \u001b[35m0.6234\u001b[0m  0.0180\n",
      "     51        0.6208       0.6900        \u001b[35m0.6220\u001b[0m  0.0209\n",
      "     52        0.6250       0.6900        \u001b[35m0.6211\u001b[0m  0.0180\n",
      "     53        \u001b[36m0.6069\u001b[0m       0.6900        \u001b[35m0.6197\u001b[0m  0.0180\n",
      "     54        \u001b[36m0.6046\u001b[0m       0.6950        \u001b[35m0.6185\u001b[0m  0.0170\n",
      "     55        0.6054       \u001b[32m0.7050\u001b[0m        \u001b[35m0.6170\u001b[0m  0.0180\n",
      "     56        0.6142       \u001b[32m0.7100\u001b[0m        \u001b[35m0.6152\u001b[0m  0.0170\n",
      "     57        0.6109       0.7050        \u001b[35m0.6142\u001b[0m  0.0259\n",
      "     58        0.6098       0.7000        \u001b[35m0.6130\u001b[0m  0.0170\n",
      "     59        \u001b[36m0.5872\u001b[0m       0.6950        \u001b[35m0.6112\u001b[0m  0.0189\n",
      "     60        \u001b[36m0.5861\u001b[0m       0.7050        \u001b[35m0.6101\u001b[0m  0.0170\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n",
      "*tweet* Accuracy reached 0.7 at epoch 48!!! #skorch #pytorch\n",
      "~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        assert len(X) == len(y)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.X)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        return self.X[i], self.y[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative = 10, random_state = 0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "dataset = MyDataset(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(ClassifierModule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error: Stratified CV requires explicitely passing a suitable y.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    net.fit(dataset, y = None)\n",
    "except ValueError as e:\n",
    "    print(\"Error:\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss     dur\n",
      "-------  ------------  -----------  ------------  ------\n",
      "      1        \u001b[36m0.7107\u001b[0m       \u001b[32m0.5000\u001b[0m        \u001b[35m0.7123\u001b[0m  0.0234\n",
      "      2        \u001b[36m0.7057\u001b[0m       0.5000        \u001b[35m0.7083\u001b[0m  0.0095\n",
      "      3        \u001b[36m0.7034\u001b[0m       0.5000        \u001b[35m0.7043\u001b[0m  0.0109\n",
      "      4        \u001b[36m0.6996\u001b[0m       \u001b[32m0.5050\u001b[0m        \u001b[35m0.7011\u001b[0m  0.0189\n",
      "      5        \u001b[36m0.6924\u001b[0m       0.5050        \u001b[35m0.6983\u001b[0m  0.0163\n",
      "      6        0.6936       \u001b[32m0.5150\u001b[0m        \u001b[35m0.6955\u001b[0m  0.0196\n",
      "      7        \u001b[36m0.6870\u001b[0m       0.5150        \u001b[35m0.6932\u001b[0m  0.0179\n",
      "      8        0.6895       \u001b[32m0.5250\u001b[0m        \u001b[35m0.6909\u001b[0m  0.0199\n",
      "      9        \u001b[36m0.6840\u001b[0m       \u001b[32m0.5350\u001b[0m        \u001b[35m0.6888\u001b[0m  0.0189\n",
      "     10        \u001b[36m0.6779\u001b[0m       \u001b[32m0.5400\u001b[0m        \u001b[35m0.6867\u001b[0m  0.0167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierModule(\n",
       "    (dense0): Linear(in_features=20, out_features=10, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (dense1): Linear(in_features=10, out_features=10, bias=True)\n",
       "    (output): Linear(in_features=10, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(dataset, y = y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_classification(1000, 20, n_informative = 10, random_state = 0)\n",
    "X = X.astype(np.float32)\n",
    "y = y.astype(np.int64)\n",
    "X0, X1 = X[:, :10], X[:, 10:]\n",
    "X_dict = {'X0': X0, 'X1': X1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  When skorch passes the dict to the pytorch module, it will pass the data as keyword arguments to the \n",
    "#  forward call. That means that we should accept the two keys XO and X1 in the forward method, as shown below:\n",
    "\n",
    "class ClassifierWithDict(nn.Module):\n",
    "    def __init__(\n",
    "            self,\n",
    "            num_units0=50,\n",
    "            num_units1=50,\n",
    "            nonlin=F.relu,\n",
    "            dropout=0.5,\n",
    "    ):\n",
    "        super(ClassifierWithDict, self).__init__()\n",
    "        self.num_units0 = num_units0\n",
    "        self.num_units1 = num_units1\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = dropout\n",
    "\n",
    "        self.dense0 = nn.Linear(10, num_units0)\n",
    "        self.dense1 = nn.Linear(10, num_units1)\n",
    "        self.nonlin = nonlin\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.output = nn.Linear(num_units0 + num_units1, 2)\n",
    "\n",
    "    def forward(self, X0, X1, **kwargs):\n",
    "        X0 = self.nonlin(self.dense0(X0))\n",
    "        X0 = self.dropout(X0)\n",
    "\n",
    "        X1 = self.nonlin(self.dense1(X1))\n",
    "        X1 = self.dropout(X1)\n",
    "\n",
    "        X = torch.cat((X0, X1), dim=1)\n",
    "        X = F.relu(X)\n",
    "        X = F.softmax(self.output(X), dim=-1)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = NeuralNetClassifier(ClassifierWithDict, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<class 'skorch.classifier.NeuralNetClassifier'>[initialized](\n",
       "  module_=ClassifierWithDict(\n",
       "    (dense0): Linear(in_features=10, out_features=50, bias=True)\n",
       "    (dense1): Linear(in_features=10, out_features=50, bias=True)\n",
       "    (dropout): Dropout(p=0.5, inplace=False)\n",
       "    (output): Linear(in_features=100, out_features=2, bias=True)\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X_dict, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Multiple return values from forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from skorch import NeuralNetRegressor\n",
    "\n",
    "class Encoder(nn.Module):\n",
    "    def __init__(self, num_units = 5):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.encode = nn.Sequential(\n",
    "            nn.Linear(20, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, self.num_units),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoded = self.encode(X)\n",
    "        return encoded\n",
    "    \n",
    "class Decoder(nn.Module):\n",
    "    def __init__(self, num_units):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "        \n",
    "        self.decode = nn.Sequential(\n",
    "            nn.Linear(self.num_units, 10),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(10, 20)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        decoded = self.decode(X)\n",
    "        return decoded\n",
    "    \n",
    "class AutoEncoder(nn.Module):\n",
    "    def __init__(self, num_units):\n",
    "        super().__init__()\n",
    "        self.num_units = num_units\n",
    "\n",
    "        self.encoder = Encoder(num_units=self.num_units)\n",
    "        self.decoder = Decoder(num_units=self.num_units)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        encoded = self.encoder(X)\n",
    "        decoded = self.decoder(encoded)\n",
    "        return decoded, encoded  # <- return a tuple of two values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoEncoderNet(NeuralNetRegressor):\n",
    "    def get_loss(self, y_pred, y_true, *args, **kwargs):\n",
    "        decoded, encoded = y_pred\n",
    "        loss_reconstruction = super().get_loss(decoded, y_true, *args, **kwargs)\n",
    "        loss_l1 = 1e-3 * torch.abs(encoded).sum()\n",
    "        return loss_reconstruction + loss_l1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "net = AutoEncoderNet(\n",
    "    AutoEncoder,\n",
    "    module__num_units = 5,\n",
    "    lr = 0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_loss     dur\n",
      "-------  ------------  ------------  ------\n",
      "      1        \u001b[36m3.8231\u001b[0m        \u001b[32m3.7714\u001b[0m  0.0808\n",
      "      2        \u001b[36m3.6923\u001b[0m        \u001b[32m3.6972\u001b[0m  0.0300\n",
      "      3        \u001b[36m3.6327\u001b[0m        \u001b[32m3.6555\u001b[0m  0.0257\n",
      "      4        \u001b[36m3.6000\u001b[0m        \u001b[32m3.6318\u001b[0m  0.0250\n",
      "      5        \u001b[36m3.5821\u001b[0m        \u001b[32m3.6186\u001b[0m  0.0250\n",
      "      6        \u001b[36m3.5724\u001b[0m        \u001b[32m3.6112\u001b[0m  0.0259\n",
      "      7        \u001b[36m3.5673\u001b[0m        \u001b[32m3.6069\u001b[0m  0.0268\n",
      "      8        \u001b[36m3.5641\u001b[0m        \u001b[32m3.6037\u001b[0m  0.0244\n",
      "      9        \u001b[36m3.5617\u001b[0m        \u001b[32m3.6007\u001b[0m  0.0250\n",
      "     10        \u001b[36m3.5589\u001b[0m        \u001b[32m3.5968\u001b[0m  0.0259\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<class '__main__.AutoEncoderNet'>[initialized](\n",
       "  module_=AutoEncoder(\n",
       "    (encoder): Encoder(\n",
       "      (encode): Sequential(\n",
       "        (0): Linear(in_features=20, out_features=10, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=10, out_features=5, bias=True)\n",
       "        (3): ReLU()\n",
       "      )\n",
       "    )\n",
       "    (decoder): Decoder(\n",
       "      (decode): Sequential(\n",
       "        (0): Linear(in_features=5, out_features=10, bias=True)\n",
       "        (1): ReLU()\n",
       "        (2): Linear(in_features=10, out_features=20, bias=True)\n",
       "      )\n",
       "    )\n",
       "  ),\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net.fit(X, X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to download data...\n",
      "Starting to extract data...\n",
      "Data has been downloaded and extracted to data.\n"
     ]
    }
   ],
   "source": [
    "def download_and_extract_data(dataset_dir = 'data'):\n",
    "    data_zip = os.path.join(dataset_dir, 'himenoptera_data.zip')\n",
    "    data_path = os.path.join(dataset_dir, 'hymenoptera_data')\n",
    "    url = \"https://download.pytorch.org/tutorial/hymenoptera_data.zip\"\n",
    "    \n",
    "    if not os.path.exists(data_path):\n",
    "        if not os.path.exists(data_zip):\n",
    "            print(\"Starting to download data...\")\n",
    "            data = request.urlopen(url, timeout = 15).read()\n",
    "            with open(data_zip, 'wb') as f:\n",
    "                f.write(data)\n",
    "                \n",
    "        print(\"Starting to extract data...\")\n",
    "        with ZipFile(data_zip, 'r') as zip_f:\n",
    "            zip_f.extractall(dataset_dir)\n",
    "            \n",
    "    print(\"Data has been downloaded and extracted to {}.\".format(dataset_dir))\n",
    "    \n",
    "download_and_extract_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = 'data/hymenoptera_data'\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.RandomResizedCrop(224),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406],\n",
    "                         [0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "train_ds = datasets.ImageFolder(\n",
    "    os.path.join(data_dir, 'train'), train_transforms)\n",
    "val_ds = datasets.ImageFolder(\n",
    "os.path.join(data_dir, 'val'), val_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PretrainedModel(nn.Module):\n",
    "    def __init__(self, output_features):\n",
    "        super().__init__()\n",
    "        model = models.resnet18(pretrained = True)\n",
    "        num_ftrs = model.fc.in_features\n",
    "        model.fc = nn.Linear(num_ftrs, output_features)\n",
    "        self.model = model\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
