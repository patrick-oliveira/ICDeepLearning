{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"Scripts/dataprep.py\"\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('C:\\\\Users\\\\Patrick\\\\Documents\\\\GitHub\\\\ICDeepLearning\\\\Codigos\\\\An√°lise de BCI\\\\Scripts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from classes import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "firstChannels = 5\n",
    "fixedSizeOutChannels = 32\n",
    "layerSize = 5\n",
    "\n",
    "inSizes = [firstChannels, fixedSizeOutChannels]\n",
    "        \n",
    "for i in range(layerSize - 2):\n",
    "    inSizes.append(inSizes[-1] + fixedSizeOutChannels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ConvBlocks(inSizes, outSizes, middleActivationFunc = 'relu', *args, **kwargs):\n",
    "    return nn.Sequential(*[ConvBlock(inputSize, outputSize, middleActivationFunc, *args, **kwargs) for\n",
    "                                     inputSize, outputSize in zip(inSizes, outSizes)])\n",
    "\n",
    "class DenseBlock(nn.Module):\n",
    "    def __init__(self, firstChannels, fixedSizeOutChannels, layerSize, kernel_size):\n",
    "        super(DenseBlock, self).__init__()\n",
    "        \n",
    "        inSizes = [firstChannels, fixedSizeOutChannels]\n",
    "        outSizes = [fixedSizeOutChannels]*layerSize\n",
    "        \n",
    "        for i in range(layerSize - 2):\n",
    "            inSizes.append(inSizes[-1] + fixedSizeOutChannels)\n",
    "            \n",
    "        self.BN = nn.BatchNorm2d(num_features = firstChannels)\n",
    "        self.ConvLayers = ConvBlocks(inSizes, outSizes, \n",
    "                                     kernel_size = kernel_size, stride = 1, padding = kernel_size//2)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.BN(X)\n",
    "        output = [self.ConvLayers[0](X)]\n",
    "        dense  = nn.ReLU(torch.cat(output, 1))\n",
    "        for conv in self.ConvLayers[1:]:\n",
    "            Y = conv(dense)\n",
    "            output.append(Y)\n",
    "            dense = nn.ReLU(torch.cat(output, 1))\n",
    "            \n",
    "        return dense    \n",
    "    \n",
    "class TransitionLayer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(TransitionLayer, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.bn   = nn.BatchNorm2d(num_features = out_channels)\n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                              kernel_size = 1, bias = False)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        bn = self.bn(self.relu(self.conv(X)))\n",
    "        out = self.avg_pool(bn)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "    \n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nr_classes):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        self.FirstConv = nn.Sequential(\n",
    "                nn.ReLU(),\n",
    "                nn.Conv2d(in_channels = 3, out_channels = 64, kernel_size = 3, bias = False)\n",
    "        )\n",
    "        \n",
    "        self.DenseLayer1 = nn.Sequential( # 160 = 32 * 5\n",
    "                DenseBlock(64, 32, 5, 3),\n",
    "                TransitionLayer(160, 128) \n",
    "        )\n",
    "        self.DenseLayer2 = nn.Sequential(\n",
    "                DenseBlock(128, 32, 5, 3),\n",
    "                TransitionLayer(160, 128)\n",
    "        )\n",
    "        self.DenseLayer3 = nn.Sequential(\n",
    "                DenseBlock(128, 32, 5, 3),\n",
    "                TransitionLayer(160, 64)\n",
    "        )\n",
    "        self.BN = nn.BatchNorm2d(num_features = 64)\n",
    "        self.Classifier = nn.Sequential(\n",
    "                nn.Linear(64*4*4, 512),\n",
    "                nn.Linear(512, nr_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.FirstConv(X)\n",
    "        X = self.DenseLayer1(X)\n",
    "        X = self.DenseLayer2(X)\n",
    "        X = self.DenseLayer3(X)\n",
    "        X = self.BN(X)\n",
    "        x.view(-1, 64*4*4)\n",
    "        X = self.Classifier(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseNet(\n",
       "  (FirstConv): Sequential(\n",
       "    (0): ReLU()\n",
       "    (1): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), bias=False)\n",
       "  )\n",
       "  (DenseLayer1): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ConvLayers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransitionLayer(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (DenseLayer2): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ConvLayers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransitionLayer(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv): Conv2d(160, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (DenseLayer3): Sequential(\n",
       "    (0): DenseBlock(\n",
       "      (BN): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (ConvLayers): Sequential(\n",
       "        (0): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (1): Sequential(\n",
       "          (0): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (2): Sequential(\n",
       "          (0): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (3): Sequential(\n",
       "          (0): Conv2d(96, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "        (4): Sequential(\n",
       "          (0): Conv2d(128, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "          (2): ReLU(inplace=True)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (1): TransitionLayer(\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (bn): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv): Conv2d(160, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (avg_pool): AvgPool2d(kernel_size=2, stride=2, padding=0)\n",
       "    )\n",
       "  )\n",
       "  (BN): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (Classifier): Sequential(\n",
       "    (0): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (1): Linear(in_features=512, out_features=5, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DenseNet(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dense_Block(nn.Module):\n",
    "    # Fa√ßa uma classe geral disso\n",
    "    def __init__(self, in_channels):\n",
    "        super(Dense_Block, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.bn   = nn.BatchNorm2d(num_features = in_channels)\n",
    "        \n",
    "        self.conv1 = nn.Conv2d(in_channels = in_channels, out_channels = 32,\n",
    "                               kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv2 = nn.Conv2d(in_channels = 32, out_channels = 32,\n",
    "                               kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv3 = nn.Conv2d(in_channels = 64, out_channels = 32, \n",
    "                               kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv4 = nn.Conv2d(in_channels = 96, out_channels = 32,\n",
    "                               kernel_size = 3, stride = 1, padding = 1)\n",
    "        self.conv5 = nn.Conv2d(in_channels = 128, out_channels = 32,\n",
    "                               kernel_size = 3, stride = 1, padding = 1)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        bn = self.bn(X)\n",
    "        conv1 = self.relu(self.conv1(bn))\n",
    "\n",
    "        conv2 = self.relu(self.conv2(conv1))\n",
    "        # Concatenate in channel dimension\n",
    "        c2_dense = self.relu(torch.cat([conv1, conv2], 1))\n",
    "\n",
    "        conv3 = self.relu(self.conv3(c2_dense))\n",
    "        c3_dense = self.relu(torch.cat([conv1, conv2, conv3], 1))\n",
    "\n",
    "        conv4 = self.relu(self.conv4(c3_dense))\n",
    "        c4_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4], 1))\n",
    "\n",
    "        conv5 = self.relu(self.conv5(c4_dense))\n",
    "        c5_dense = self.relu(torch.cat([conv1, conv2, conv3, conv4, conv5], 1))\n",
    "\n",
    "        return c5_dense\n",
    "    \n",
    "class Transition_Layer(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(Transition_Layer, self).__init__()\n",
    "        \n",
    "        self.relu = nn.ReLU(inplace = True)\n",
    "        self.bn   = nn.BatchNorm2d(num_features = out_channels)\n",
    "        self.conv = nn.Conv2d(in_channels = in_channels, out_channels = out_channels,\n",
    "                              kernel_size = 1, bias = False)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size = 2, stride = 2, padding = 0)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        bn = self.bn(self.relu(self.conv(X)))\n",
    "        out = self.avg_pool(bn)\n",
    "        \n",
    "        return out\n",
    "    \n",
    "class DenseNet(nn.Module):\n",
    "    def __init__(self, nr_classes):\n",
    "        super(DenseNet, self).__init__()\n",
    "        \n",
    "        self.lowconv = nn.Conv2d(in_channels = 3, out_channels = 64, \n",
    "                                 kernel_size = 3, bias = False)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "        # Dense Blocks\n",
    "        self.denseblock1 = self._make_dense_block(Dense_Block, 64)\n",
    "        self.denseblock2 = self._make_dense_block(Dense_Block, 128)\n",
    "        self.denseblock3 = self._make_dense_block(Dense_Block, 128)\n",
    "        \n",
    "        # Make transition Layers\n",
    "        self.transitionLayer1 = self._make_transition_layer(Transition_Layer,\n",
    "                                                            in_channels = 160, out_channels = 128)\n",
    "        self.transitionLayer2 = self._make_transition_layer(Transition_Layer,\n",
    "                                                            in_channels = 160, out_channels = 128)\n",
    "        self.transitionLayer3 = self._make_transition_layer(Transition_Layer,\n",
    "                                                            in_channels = 160, out_channels = 64)\n",
    "        \n",
    "        # Classifier\n",
    "        self.bn = nn.BatchNorm2d(num_features = 64)\n",
    "        self.pre_classifier = nn.Linear(64*4*4, 512)\n",
    "        self.classifier = nn.Linear(512, nr_classes)\n",
    "        \n",
    "    def _make_dense_block(self, block, in_channels):\n",
    "        layers = []\n",
    "        layers.append(block(in_channels))\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def _make_transition_layer(self, layer, in_channels, out_channels):\n",
    "        modules = []\n",
    "        modules.append(layer(in_channels, out_channels))\n",
    "        return nn.Sequential(*modules)\n",
    "    \n",
    "    def forward(self, X):\n",
    "        out = self.relu(self.lowconv(X))\n",
    "        \n",
    "        out = self.denseblock1(out)\n",
    "        out = self.transitionLayer1(out)\n",
    "        \n",
    "        out = self.denseblock2(out)\n",
    "        out = self.transitionLayer2(out)\n",
    "        \n",
    "        out = self.denseblock3(out)\n",
    "        out = self.transitionLayer3(out)\n",
    "        \n",
    "        out = self.bn(out)\n",
    "        out = out.view(-1, 64*4*4)\n",
    "        \n",
    "        out = self.pre_classifier(out)\n",
    "        out = self.classifier(out)\n",
    "        \n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
