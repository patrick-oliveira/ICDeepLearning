{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import sys\n",
    "sys.path.append('Scripts')\n",
    "\n",
    "from SignalDataset import SignalDataset\n",
    "from Dataloader import Dataloader\n",
    "from SSVEPDataset import SSVEPSignalDataset\n",
    "from SSVEPDataloader import SSVEPDataloaders\n",
    "from utils import generate_time_series\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from TrainingFunc import train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %run \"SignalDatasetCreator.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = SignalDataset()\n",
    "dataloaders, dataset_sizes = Dataloader(dataset, batch_size = 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = '512'\n",
    "data = pd.read_csv('SSVEPDatasetPCA_'+dataType+'.csv')\n",
    "ssvep_dataset = SSVEPSignalDataset(data)\n",
    "ssvep_dataloaders, ssvep_datasets_izes = Dataloader(ssvep_dataset, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Model, self).__init__()\n",
    "        self.Linear1 = nn.Linear(512, 300)\n",
    "        self.Linear2 = nn.Linear(300, 100)\n",
    "        self.Linear3 = nn.Linear(100, 11)\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.Linear1(X)\n",
    "        X = self.Linear2(X)\n",
    "        X = self.Linear3(X)\n",
    "        return X\n",
    "\n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "model = Model().double().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/1\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0001 Acc: 1.0000\n",
      "\n",
      "Epoch 1/1\n",
      "----------\n",
      "train Loss: 0.0001 Acc: 1.0000\n",
      "val Loss: 0.0001 Acc: 1.0000\n",
      "\n",
      "Training complete in 0m 1s\n",
      "Best val Acc: 1.000000\n"
     ]
    }
   ],
   "source": [
    "model, training_stats, validation_stats = train(model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, device,\n",
    "                                                num_epochs = 2)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0000 Acc: 1.0000\n"
     ]
    }
   ],
   "source": [
    "test(model, dataloaders['test'], dataset_sizes['test'], criterion, device)\n",
    "\n",
    "path = 'C:\\\\Users\\\\Patrick\\\\Documents\\\\GitHub\\\\ICDeepLearning\\\\Data\\\\Models\\\\SignalSelector'\n",
    "torch.save(model.state_dict(), path+'\\\\selector.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'C:\\\\Users\\\\Patrick\\\\Documents\\\\GitHub\\\\ICDeepLearning\\\\Data\\\\ProcessedSignals\\\\512'\n",
    "ssvep_dataloaders, _ = Dataloader(ssvep_dataset, batch_size = 1)\n",
    "alpha = 10\n",
    "i = [-1, -1, -1, -1, -1]\n",
    "data = pd.DataFrame(columns = ['subject', 'state', 'path'])\n",
    "for t in ['train', 'val', 'test']:\n",
    "    dataloader = ssvep_dataloaders[t]\n",
    "    for sample in dataloader:\n",
    "        c = sample['class'].item()\n",
    "        i[c] += 1\n",
    "        state = c + 1\n",
    "        new_path = path+'\\\\'+str(state)\n",
    "\n",
    "        signal = sample['signal'].squeeze(0)\n",
    "\n",
    "        _, frequency = torch.max(model(signal.to(device)), 1)\n",
    "        frequency = frequency.item()\n",
    "\n",
    "        signal = signal.numpy() + generate_time_series(frequency = frequency)\n",
    "\n",
    "        new_path = new_path+'\\\\'+str(i[c])+'.csv'\n",
    "        np.savetxt(new_path, signal)\n",
    "        \n",
    "        temp = pd.DataFrame([['_', state, new_path]] , columns = ['subject', 'state', 'path'])\n",
    "        data = pd.concat([data, temp], axis = 0)\n",
    "        \n",
    "data.to_csv('SSVEPDatasetProcessed_512.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
