{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Scripts')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils, datasets, models\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.utils.data.sampler import SubsetRandomSampler\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import path, batchVisualization, createInputFigure\n",
    "from SSVEPDataset import SSVEPDataset\n",
    "from classes import *\n",
    "from SSVEPDataloader import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import time\n",
    "import copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\Patrick\\Documents\\GitHub\\ICDeepLearning\\Data loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def read_data(dataframe, path, ind):\n",
    "    return torch.tensor(pd.read_csv(path/dataframe.loc[ind]['path'],  sep = ' ', usecols = range(16), names = range(1, 17), dtype = float).values)\n",
    "\n",
    "#dataPath = path('/home/roboto/Documents/GitHub/ICDeepLearning/Data')\n",
    "dataPath = path('C:\\\\Users\\\\Patrick\\\\Documents\\\\GitHub\\\\ICDeepLearning\\\\Data')\n",
    "data = pd.read_csv('SSVEPDataset.csv')\n",
    "dataset = SSVEPDataset(data, dataPath)\n",
    "\n",
    "batchSize = 1\n",
    "dataloaders, datasetsSizes = SSVEPDataloaders(dataset, batchSize)\n",
    "# example = next(iter(dataloaders['train']))['series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convOutputSize(i, k, p, s):\n",
    "    return int(np.floor((i + 2*p - k)/s + 1))\n",
    "\n",
    "def deconvOutputsize(i, k, p, s):\n",
    "    if s == 1 and p == 0:\n",
    "        return i + k - 1\n",
    "    if (not k%2 == 0) and s == 1 and p == np.floor(k/2):\n",
    "        return i\n",
    "    if (i - k)%2 == 0:\n",
    "        return \n",
    "\n",
    "def maxpoolOutputShape(i, k, p, s, d):\n",
    "    return np.floor((i + 2*p - d*(k - 1) - 1)/s + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16\n"
     ]
    }
   ],
   "source": [
    "parameters = [16, 5, 2, 1]\n",
    "\n",
    "print(convOutputSize(*parameters))\n",
    "#print(deconvOutputsize(*parameters))\n",
    "#print(maxpoolOutputShape(512, 3, 1, 2, 1))\n",
    "#print(maxpoolOutputShape(16, 3, 1, 1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            ConvBlock(1, 16, kernel_size = [3, 3], padding = [1, 1]),\n",
    "            ConvBlock(16, 32, kernel_size = [3, 3], padding = [1, 1]),\n",
    "            ConvBlock(32, 64, kernel_size = [3, 3], padding = [1, 1]),\n",
    "            nn.MaxPool2d(kernel_size = [3, 3], stride = [2, 1], padding = [1, 1])\n",
    "        )\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.UpsamplingNearest2d(scale_factor = (2, 1)),\n",
    "            DeconvBlock(64, 32, kernel_size = [3, 3], padding = [1, 1]),\n",
    "            DeconvBlock(32, 16, kernel_size = [3, 3], padding = [1, 1]),\n",
    "            DeconvBlock(16, 1, kernel_size = [3, 3], padding = [1, 1])\n",
    "        )\n",
    "        \n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "        X = self.decoder(X)\n",
    "        return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 16])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.1008],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0043],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.0000, 0.0000],\n",
       "          ...,\n",
       "          [0.0000, 0.0000, 0.0587,  ..., 0.0000, 0.0415, 0.6923],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.0000, 0.9468, 1.1862],\n",
       "          [0.0000, 0.0000, 0.0000,  ..., 0.2293, 2.4679, 1.0508]]]],\n",
       "       dtype=torch.float64, grad_fn=<ReluBackward1>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = Autoencoder().double()\n",
    "model(next(iter(dataloaders['train']))['series'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def train(model, dataloader, num_epochs = 5, batch_size = 16, learning_rate = 1e-3):\n",
    "#     torch.manual_seed(42)\n",
    "#     criterion = nn.MSELoss()\n",
    "#     optimizer = torch.optim.Adam(model.parameters(),\n",
    "#                                  lr = learning_rate,\n",
    "#                                  weight_decay = 1e-5)\n",
    "    \n",
    "#     train_loader = dataloader['train']\n",
    "    \n",
    "#     outputs = []\n",
    "#     for epoch in range(num_epochs):\n",
    "#         for data in train_loader:\n",
    "#             img = data['series']\n",
    "#             recon = model(img)\n",
    "#             loss = criterion(recon, img)\n",
    "#             loss.backward()\n",
    "#             optimizer.step()\n",
    "#             optimizer.zero_grad()\n",
    "            \n",
    "#         print('Epoch:{}, Loss:{:.4f}'.format(epoch+1, float(loss)))\n",
    "#         outputs.append((epoch, img, recon),)\n",
    "    \n",
    "#     return outputs\n",
    "\n",
    "def train(model, dataloaders, criterion, optimizer, scheduler, device,\n",
    "          num_epochs = 25, learningRate = 1e-3):\n",
    "    since = time.time()\n",
    "    bestModel = copy.deepcopy(model.state_dict())\n",
    "    bestLoss = 0.0\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and a validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            runningLoss = 0.0\n",
    "            runningCorrects = 0\n",
    "            \n",
    "            for inputs in dataloaders[phase]:\n",
    "                inputs = inputs['series'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, inputs)\n",
    "                    \n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                runningLoss += loss.item() * inputs.size(0)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            epochLoss = runningLoss/datasetsSizes[phase]\n",
    "            \n",
    "            print('{} Loss: {:.4f}'.format(phase, epochLoss))\n",
    "            \n",
    "            if phase == 'val' and epochLoss > bestLoss:\n",
    "                bestLoss = epochLoss\n",
    "                best_model = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(bestLoss))\n",
    "    \n",
    "    model.load_state_dict(best_model)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/9\n",
      "----------\n",
      "train Loss: 0.0294\n",
      "val Loss: 0.0234\n",
      "\n",
      "Epoch 1/9\n",
      "----------\n",
      "train Loss: 0.0233\n",
      "val Loss: 0.0217\n",
      "\n",
      "Epoch 2/9\n",
      "----------\n",
      "train Loss: 0.0222\n",
      "val Loss: 0.0219\n",
      "\n",
      "Epoch 3/9\n",
      "----------\n",
      "train Loss: 0.0216\n",
      "val Loss: 0.0220\n",
      "\n",
      "Epoch 4/9\n",
      "----------\n",
      "train Loss: 0.0212\n",
      "val Loss: 0.0240\n",
      "\n",
      "Epoch 5/9\n",
      "----------\n",
      "train Loss: 0.0206\n",
      "val Loss: 0.0226\n",
      "\n",
      "Epoch 6/9\n",
      "----------\n",
      "train Loss: 0.0269\n",
      "val Loss: 0.0267\n",
      "\n",
      "Epoch 7/9\n",
      "----------\n",
      "train Loss: 0.0232\n",
      "val Loss: 0.0265\n",
      "\n",
      "Epoch 8/9\n",
      "----------\n",
      "train Loss: 0.0228\n",
      "val Loss: 0.0255\n",
      "\n",
      "Epoch 9/9\n",
      "----------\n",
      "train Loss: 0.0225\n",
      "val Loss: 0.0258\n",
      "\n",
      "Training complete in 12m 36s\n",
      "Best val Loss: 0.026675\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "model = Autoencoder().double()\n",
    "model = model.to(device)\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)\n",
    "\n",
    "model = train(model, dataloaders, criterion, optimizer, scheduler, device,\n",
    "              num_epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Autoencoder().double()\n",
    "max_epochs = 20\n",
    "outputs = train(model, dataloaders, num_epochs = max_epochs)\n",
    "outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
