{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('Scripts')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from utils import path, batchVisualization, createInputFigure\n",
    "from dataprep import dataprep\n",
    "from SSVEPDataset import SSVEPDataset\n",
    "from classes import *\n",
    "from SSVEPDataloader import *\n",
    "\n",
    "from sklearn import preprocessing\n",
    "import os\n",
    "import time\n",
    "import copy\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataframe):\n",
    "    return pd.read_csv(dataframe['path'], sep = ' ', header = None, dtype = np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "Primeira tentativa: combinação por proporção simples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataType = '768'\n",
    "dataprep(dataType)\n",
    "data = pd.read_csv('SSVEPDataset_'+dataType+'.csv')\n",
    "combData = pd.DataFrame(columns = ['subject', 'path', \"state\"])\n",
    "for i in range(len(data)):\n",
    "    indData = data.loc[i]\n",
    "    sample = read_data(indData).values.T\n",
    "#     sample = pd.read_csv(indData['path'], sep = ' ', usecols = range(16), names = range(1, 17), dtype = float)\n",
    "    series = (sample[2] + sample[11])/2\n",
    "    \n",
    "#     for j in range(4, 16):\n",
    "#         series += (0.4/13)*sample[j]\n",
    "        \n",
    "    newPath = indData['path'].replace('Originais', 'Dados_BCI_Combinados')\n",
    "    tempRow = pd.DataFrame([[indData['subject'], newPath, indData['state']]], columns = ['subject', 'path', 'state'])\n",
    "    combData = combData.append(tempRow)\n",
    "    np.savetxt(newPath, series)\n",
    "#     series.to_csv(newPath+\".csv\", index = False)\n",
    "\n",
    "combData.to_csv(\"SSVEPDatasetCombined_\"+dataType+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "Segunda tentativa: PCA\n",
    "\n",
    "A variância explicada é baixa demais."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Patrick\\Anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_pca.py:545: RuntimeWarning: invalid value encountered in true_divide\n",
      "  self.explained_variance_ / total_var.sum()\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "pca = PCA(n_components = 3)\n",
    "\n",
    "dataType = '768'\n",
    "dataprep(dataType)\n",
    "data = pd.read_csv('SSVEPDataset_'+dataType+'.csv')\n",
    "combData = pd.DataFrame(columns = ['subject', 'path', \"state\"])\n",
    "for i in range(len(data)):\n",
    "    indData = data.loc[i]\n",
    "    sample = read_data(indData).values\n",
    "    pca.fit(sample)\n",
    "    C1, C2, C3 = pca.components_\n",
    "    series = (C1.dot(sample.T) + C2.dot(sample.T) + C3.dot(sample.T))/3\n",
    "    \n",
    "    newPath = indData['path'].replace('Originais', 'Dados_BCI_CombinadosPCA')\n",
    "    tempRow = pd.DataFrame([[indData['subject'], newPath, indData['state']]], columns = ['subject', 'path', 'state'])\n",
    "    combData = combData.append(tempRow)\n",
    "    np.savetxt(newPath, series)\n",
    "    \n",
    "combData.to_csv(\"SSVEPDatasetPCA_\"+dataType+\".csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Terceira Tentativa: Utilizar um autoencoder para fazer a combinação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory C:\\Users\\Patrick\\Documents\\GitHub\\ICDeepLearning\\Data\\Originais\\512 loaded successfully.\n"
     ]
    }
   ],
   "source": [
    "def read_data(dataframe, path, ind):\n",
    "    return torch.tensor(pd.read_csv(path/dataframe.loc[ind]['path'],  sep = ' ', usecols = range(16), names = range(1, 17), dtype = float).values)\n",
    "\n",
    "dataType = '512'\n",
    "#dataPath = path('/home/roboto/Documents/GitHub/ICDeepLearning/Data/Originais')\n",
    "dataPath = path('C:\\\\Users\\\\Patrick\\\\Documents\\\\GitHub\\\\ICDeepLearning\\\\Data\\\\Originais\\\\'+dataType)\n",
    "data = pd.read_csv('SSVEPDataset.csv')\n",
    "dataset = SSVEPDataset(data, dataPath)\n",
    "\n",
    "batchSize = 64\n",
    "dataloaders, datasetsSizes = SSVEPDataloaders(dataset, batchSize)\n",
    "# example = next(iter(dataloaders['train']))['series']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ** Training algorithms\n",
    "\n",
    "def train(model, dataloaders, criterion, optimizer, scheduler, device,\n",
    "          num_epochs = 25, learningRate = 1e-3):\n",
    "    since = time.time()\n",
    "    bestModel = copy.deepcopy(model.state_dict())\n",
    "    bestLoss = np.inf\n",
    "    \n",
    "    trainLoss = []\n",
    "    validLoss = []\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "        \n",
    "        # Each epoch has a training and a validation phase\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()\n",
    "            else:\n",
    "                model.eval()\n",
    "                \n",
    "            runningLoss = 0.0\n",
    "            runningCorrects = 0\n",
    "            \n",
    "            for inputs in dataloaders[phase]:\n",
    "                inputs = inputs['series'].to(device)\n",
    "                \n",
    "                optimizer.zero_grad()\n",
    "                \n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    loss = criterion(outputs, inputs)\n",
    "                    \n",
    "                    \n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "                        \n",
    "                runningLoss += loss.item() * inputs.size(0)\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "                \n",
    "            epochLoss = runningLoss/datasetsSizes[phase]\n",
    "            \n",
    "            if phase == 'train':\n",
    "                trainLoss.append(epochLoss)\n",
    "            else:\n",
    "                validLoss.append(epochLoss)\n",
    "            \n",
    "            print('{} Loss: {:.4f}'.format(phase, epochLoss))\n",
    "            \n",
    "            if phase == 'val' and epochLoss < bestLoss:\n",
    "                bestLoss = epochLoss\n",
    "                bestModel = copy.deepcopy(model.state_dict())\n",
    "                \n",
    "        print()\n",
    "        \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Loss: {:4f}'.format(bestLoss))\n",
    "    \n",
    "    model.load_state_dict(bestModel)\n",
    "    return model, [trainLoss, validLoss], bestLoss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataVisualization(X):\n",
    "    X = X.squeeze().T\n",
    "    \n",
    "    fig = plt.figure(figsize = (15, 15))\n",
    "    ax = fig.add_subplot()\n",
    "    ax.imshow(X, cmap = 'gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Resize(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        size = X.shape[0]\n",
    "        return X.view(size, 1, 512, 16)\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self,):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = nn.Sequential(\n",
    "            *ConvBlocks([1, 16], kernel_size = [5, 5], padding = [2, 2]),\n",
    "            ConvBlock(16, 1, kernel_size = [1, 16])\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            *ConvBlocks([1, 16], kernel_size = [5, 1], padding = [2, 0]),\n",
    "            Resize()\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        X = self.encoder(X)\n",
    "        X = self.decoder(X)\n",
    "        return X\n",
    "    \n",
    "    \n",
    "device = torch.device(\"cuda:0\" if (torch.cuda.is_available()) else \"cpu\")\n",
    "\n",
    "model = Autoencoder().double().to(device)\n",
    "\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.01)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory Models\\Autoencoders loaded successfully.\n",
      "Epoch 0/19\n",
      "----------\n",
      "train Loss: 3.1138\n",
      "val Loss: 3.0153\n",
      "\n",
      "Epoch 1/19\n",
      "----------\n",
      "train Loss: 2.7598\n",
      "val Loss: 3.2261\n",
      "\n",
      "Epoch 2/19\n",
      "----------\n",
      "train Loss: 2.6216\n",
      "val Loss: 2.7668\n",
      "\n",
      "Epoch 3/19\n",
      "----------\n",
      "train Loss: 2.5670\n",
      "val Loss: 2.6530\n",
      "\n",
      "Epoch 4/19\n",
      "----------\n",
      "train Loss: 2.5689\n",
      "val Loss: 2.6851\n",
      "\n",
      "Epoch 5/19\n",
      "----------\n",
      "train Loss: 2.5303\n",
      "val Loss: 2.6431\n",
      "\n",
      "Epoch 6/19\n",
      "----------\n",
      "train Loss: 2.5419\n",
      "val Loss: 2.6826\n",
      "\n",
      "Epoch 7/19\n",
      "----------\n",
      "train Loss: 2.5308\n",
      "val Loss: 2.6397\n",
      "\n",
      "Epoch 8/19\n",
      "----------\n",
      "train Loss: 2.5384\n",
      "val Loss: 2.6399\n",
      "\n",
      "Epoch 9/19\n",
      "----------\n",
      "train Loss: 2.5101\n",
      "val Loss: 2.6384\n",
      "\n",
      "Epoch 10/19\n",
      "----------\n",
      "train Loss: 2.5581\n",
      "val Loss: 2.6509\n",
      "\n",
      "Epoch 11/19\n",
      "----------\n",
      "train Loss: 2.5131\n",
      "val Loss: 2.6390\n",
      "\n",
      "Epoch 12/19\n",
      "----------\n",
      "train Loss: 2.5223\n",
      "val Loss: 2.6372\n",
      "\n",
      "Epoch 13/19\n",
      "----------\n",
      "train Loss: 2.5206\n",
      "val Loss: 2.6367\n",
      "\n",
      "Epoch 14/19\n",
      "----------\n",
      "train Loss: 2.5234\n",
      "val Loss: 2.6389\n",
      "\n",
      "Epoch 15/19\n",
      "----------\n",
      "train Loss: 2.5294\n",
      "val Loss: 2.6444\n",
      "\n",
      "Epoch 16/19\n",
      "----------\n",
      "train Loss: 2.5407\n",
      "val Loss: 2.6401\n",
      "\n",
      "Epoch 17/19\n",
      "----------\n",
      "train Loss: 2.5183\n",
      "val Loss: 2.6531\n",
      "\n",
      "Epoch 18/19\n",
      "----------\n",
      "train Loss: 2.5132\n",
      "val Loss: 2.6377\n",
      "\n",
      "Epoch 19/19\n",
      "----------\n",
      "train Loss: 2.5197\n",
      "val Loss: 2.6482\n",
      "\n",
      "Training complete in 3m 21s\n",
      "Best val Loss: 2.636651\n"
     ]
    }
   ],
   "source": [
    "n = n + 1\n",
    "modelPath = path('Models\\\\Autoencoders\\\\SeriesCombination')\n",
    "modelName = 'Autoencoder'+str(n)\n",
    "file = open(modelPath/modelName+\".txt\", 'w')\n",
    "\n",
    "model, stats, bestLoss = train(model, dataloaders, criterion, optimizer, scheduler, device,\n",
    "                         num_epochs = 20)\n",
    "\n",
    "file.write(str(model)+\"\\n\\n\")\n",
    "file.write(\"Best Val Loss:{}\\n\\n\".format(bestLoss))\n",
    "file.write(\"Training Loss: {}\\n\\n\".format(stats[0]))\n",
    "file.write(\"Validation Loss: {}\\n\\n\".format(stats[1]))\n",
    "file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "exemplo = iter(dataloaders['train']).next()['series']\n",
    "model = model.to('cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "dataVisualization(exemplo[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2cAAAA8CAYAAADi6sLMAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAPdUlEQVR4nO3dfYxVdX7H8ff33hkGH2bKAIIItKCislGx1lgN/oFuqWxLQJMlQvpgjJV/bLNNbBramDRtsrH9pzRNTRPSmlVolxLa3TWVpDVCXU0qFV3qDrU8FEHJEIZnEORp5ts/7vnNXGeHYZh75vzO/c3nlZC559xz7/n+ON/z8Hs455q7IyIiIiIiInFVYgcgIiIiIiIiqpyJiIiIiIiUgipnIiIiIiIiJaDKmYiIiIiISAmociYiIiIiIlICqpyJiIiIiIiUQEOVMzNbYma7zWyfma3JKygREREREZHxxkb7O2dmVgX2AIuBQ8CHwCp3/5/8whMRERERERkfGuk5exjY5+773f0SsBFYnk9YIiIiIiIi40tLA5+dCXxRN30I+OXBC5nZamA1QLVa/aWOjg5mzpzZwGrL44svasWfPXt25Ejy09XVxb333hs7jIaFHuGDBw8CMGfOnIjR5MPdOXz4MEAS+1DYRqnl3IEDBwCYO3duxGjy4e60tbUBcPny5cjR5OOzzz4D0tk+APv37+f222+PHE3jQnlOnToFQGdnZ8xwctPV1QWQ1HFu165dyZUH0tlGoTz33HNP5GgaF7bR7t27k9k+ALt27Trm7rcMtUwjwxpXAE+6++9k078FPOzuv3e1z0ydOtWXLVvGyy+/jJl9LchmtGZN7Ta7V155BaC/TM1swYIF7Ny5M3YYDevt7QVg06ZNAKxcufJrOdfItgo5a2Zfez3SzwwVw1DvDyVctEydOnW04ZdGKOucOXPYu3dv5GgaFyov69atA+DFF1+MGU5u7rzzTmCg0tnM2traeOGFFwB49dVXI0fTuHCcWLVqFRs2bIgcTeP6+voAOH36NJBG5axarfL0008DsHnz5sjRNC5so5deeom1a9dGjqZxoTwrV64EBq4ZmllfXx933XUXANu3b48cTeOuXLkCwMKFC9m3b1/kaBoXrhXmz5//kbs/NNQyjfScHQLqu4xmAd3DfaC9vZ3HH3+8gVWWR7VaZfHixUAalbJKpTbC9bnnnoscST5CecKFZbMYrrGiWq32H6RSUK1WAXjmmWciR5KPkHP3339/5EjyU6lUuHDhQuwwctPS0sLSpUtjh5GbsA+tWLEiciT5COUJ+1IKWlpaWLJkSewwchO2zYMPPhg5knyE8jz55JORI8lPpVJJ5pgAA9to+fI07pwayfGtkSPgh8A8M5trZhOAlcCbDXyfiIiIiIjIuDXqnjN3v2Jmvwv8G1AFXnP3XcN9prW1lWnTpo12laVSrVa59dZbY4eRm9BimcL4ZBhombjtttsa+p6RDlts1ODhjEMNmaxWq0yfPn1M4yhSS0vt8LNgwYLIkeQj7EMp3A8YpNZbW6lUGj4mlElqORfK09HRETmS/FQqlWTOqzBwbp0/f37kSPKR2rUP1LZRKtsHBrbRo48+2j+vmW+NCuUZTiPDGnH3LcCWRr5DREREREREGqycXffKWlqSeJAB1Fommr0XsP6hFOFvCk/8goFemZG2wDb6kJDB3wVf723L47srlUr/zcspSK3FMpQnhYcYBJVKhUuXLsUOI1czZsyIHUJuQs6l0hsYemVCuVI43lUqFWbNmhU7jNyEbZPKyKGQc6n0PkNtG82bNy92GLkJ13N333135EjyEcoz7DIFxNGvUqlw4403FrnKMVOpVLjpppsa/p48KwWNCAeoKVOmRI4kH6E8N9xwQ+RI8lPfFZ7CULOwjVIZqhkOuCnlnJklVTnr6+vj5ptvjh1GbsI+lMowwMGNhamYNGlS7BByk1rOhfKkto1S6QiBgWufVK4VRjKsMZ1HIomIiIiIiDSxQnvOzKy/dbkZb+IbrLW1NXYIuQktlam0+oeWiZF0HwdFPfxDasL/d3t7e+RI8hFybsKECZEjyVcqPz4Ntd8/TGn7hGNVKmUK+1BKOdfX15fMiCEY2EapXSvkMRKqLKrValI5F3o3668VmrkOMZK6g3rORERERERESqDQnjNozh+XrH+seeDuIxo3WnahXOFvW1tbzHByM1zvV7P2jLl7EjfIB6EsKeScmfUf25o1v66mt7c3dggNC8e3y5cvJ3HcDkK5rmeEQDNI6TjX29ub1CiboNGcK8tIlVT3oVR602Gg3pBCmcxsRDlfeDbG3hFHaqgKWb3e3t6mKctIhJNhM1aeh1OWE8Bg1xNPKENfX19SFy3hoSap5FxKDzOoz7kUpFo5S+24nUJDQBByLrVrhWYeTjaUsA+lto1SOCYM3iapbKORlKP5t56IiIiIiEgCrlk5M7PXzKzHzLrq5k02s7fNbG/2N50f9hmhVFqUg97e3qRaLceyl6m+W3pwF/VYtiqmsn3cHXfnypUrSfwkQJBazyakl3Mp/SwApHXcDsO2U9mHQs6l9HATSOs4F7ZRqr2BzS5sm5RyDka2D42k5+x7wJJB89YA77j7POCdbFpERERERERG6ZqVM3f/MXBi0OzlwOvZ69eBp3KOq7RSaw0L5bl48SIXL16MHU5uytrSMppWuvCZlFrI3Z0LFy5w4cKF2OHkIvyYfCpj4lPraQrl+fLLL2OHkpvx2qLcLOrPrSmov/ZJ5foH0ut9Tun6NEUjvf4b7T1n0939cLaiw8C0qy1oZqvNbIeZ7ThxYnAdT0RERERERKCAB4K4+zp3f8jdH5o8efJYr27M5d2iHLulPZTn/PnznD9/Pmoseblay0RZx5ZfK6b6e7RSkGpvbaVSSeIJWTCwjb766qvYoeQilKe7uzt2KLlJrRcjtftQQ86dOnUqdii5unTpUi7XP2UYaRCu5VIZIRCkcl4N+1Bra2vT/hzFaPN8tFcSR8xsRrbiGUDPKL+ntK51gX/y5MmCIxpbR48e5ejRo7HDyMVoKmBhB2r0ZDHU5xutENZXoFNy/Phxjh8/HjuMXLg7bW1tSfxmW71URjuEfeiDDz6IHUpuwjDNVIZqptZIGHz++eexQ8hF2IfOnTvHuXPnYoeTixSH16c0fDuUJ6Vz60jLM9rK2ZvAs9nrZ4EfjfJ7REREREREhJE9Sv/7wH8Cd5vZITN7HvhzYLGZ7QUWZ9PJGqrnI5XhMaFl4siRIxw5ciR2OLlwd86ePcvZs2cb/q6yDL1wdw4dOhQ1jryE8vT09NDTk0ane19fX5JDso4dOxY7lFyE/fi9996LHUpu3J2DBw9y8ODB2KHkIrXzUPDJJ5/EDiEXqd4CcezYsWSOc/UP20pBKE9e13MxDL6dJjz06FoPPmoZwRevuspb37yuCEVEREREROSq0rh7PYKPP/44dgi52rp1K1u3bo0dRi7G8qEfMR8osn///mjrHgvr169n/fr1scPIhbvT0dFBR0dH7FBytW3bttgh5CI8rOX999+PHUquUutp6u7uTmZUSvDWW2/FDiFXe/bsYc+ePbHDyM2ZM2c4c+ZM7DBytXPnztgh5CL0OnV2dtLZ2Rk7nFy4OxMnTmTixInDLnfNnrOxYGalfGre9UhhqEL9kL1UbiCFWvKHE+JTT43dT/CF37Yaa2EdW7ZsYdmyZWO+vrEWytPe3h45kvy4e3/jxh133BE5msaldlyoVquxQ8idmfHGG28AsGjRorjB5CTsQ4899ljkSBoXntza1dUVOZJ8hGu2VB7iFGzcuBGA++67L3IkjQvbqFmfbDhYGPq3YcMGAFasWBEznFy4O+++++41l1PPmYiIiIiISAlYkT1YZnYUOAekcfelNLupKBelPJSPUhbKRSkT5aOURZ65+AvufstQbxRaOQMwsx3u/lChKxUZgnJRykT5KGWhXJQyUT5KWRSVixrWKCIiIiIiUgKqnImIiIiIiJRAjMrZugjrFBmKclHKRPkoZaFclDJRPkpZFJKLhd9zJiIiIiIiIj9LwxpFRERERERKQJUzERERERGREiiscmZmS8xst5ntM7M1Ra1Xxi8ze83Mesysq27eZDN728z2Zn87s/lmZn+d5ecnZvZgvMglNWY228y2mdmnZrbLzL6TzVc+SqHMbKKZ/ZeZ/XeWi3+azZ9rZtuzXPwnM5uQzW/Lpvdl78+JGb+kycyqZvYTM/vXbFr5KIUzswNm9lMz22lmO7J5hZ+nC6mcmVkVeBX4FvANYJWZfaOIdcu49j1gyaB5a4B33H0e8E42DbXcnJf9Ww38bUExyvhwBXjJ3ecDjwAvZsdA5aMU7SLwhLsvAB4AlpjZI8BfAGuzXDwJPJ8t/zxw0t3vBNZmy4nk7TvAp3XTykeJ5XF3f6Du98wKP08X1XP2MLDP3fe7+yVgI7C8oHXLOOXuPwZODJq9HHg9e/068FTd/De85gNgkpnNKCZSSZ27H3b3j7PXZ6ldhMxE+SgFy3Lqy2yyNfvnwBPA5mz+4FwMOboZ+KaZWUHhyjhgZrOAXwf+Lps2lI9SHoWfp4uqnM0EvqibPpTNEynadHc/DLULZmBaNl85KoXIhuH8IrAd5aNEkA0h2wn0AG8D/weccvcr2SL1+dafi9n7p4EpxUYsifsr4A+Bvmx6CspHicOBfzezj8xsdTav8PN0Sx5fMgJDtWroGf5SJspRGXNmdjPwz8Dvu/uZYRp8lY8yZty9F3jAzCYBPwDmD7VY9le5KGPGzJYCPe7+kZktCrOHWFT5KEVY6O7dZjYNeNvM/neYZccsF4vqOTsEzK6bngV0F7RukXpHQrdz9rcnm68clTFlZq3UKmb/4O7/ks1WPko07n4K+A9q90FOMrPQYFufb/25mL3/c/zscHGR0VoILDOzA9RueXmCWk+a8lEK5+7d2d8eag1XDxPhPF1U5exDYF729J0JwErgzYLWLVLvTeDZ7PWzwI/q5v929vSdR4DToRtbpFHZPRF/D3zq7n9Z95byUQplZrdkPWaY2Q3Ar1C7B3Ib8O1sscG5GHL028BWd1dPheTC3f/I3We5+xxq14Zb3f03UD5KwczsJjNrD6+BXwW6iHCetqJy2sx+jVprSBV4zd2/W8iKZdwys+8Di4CpwBHgT4AfApuAnwc+B1a4+4ns4vlvqD3d8TzwnLvviBG3pMfMHgPeA37KwH0Vf0ztvjPloxTGzO6ndlN7lVoD7SZ3/zMzu51az8Vk4CfAb7r7RTObCKyndp/kCWClu++PE72kLBvW+AfuvlT5KEXLcu4H2WQL8I/u/l0zm0LB5+nCKmciIiIiIiJydYX9CLWIiIiIiIhcnSpnIiIiIiIiJaDKmYiIiIiISAmociYiIiIiIlICqpyJiIiIiIiUgCpnIiIiIiIiJaDKmYiIiIiISAn8P8Rh5y8mT5kyAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1080 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = model(exemplo)[0].detach().numpy()\n",
    "dataVisualization(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
