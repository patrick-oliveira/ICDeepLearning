{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 17,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "from Project import Project\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from itertools import product\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Scripts.neuralnets.NNPreinstalledModelSelection import *\n",
    "from Scripts.neuralnets.NNTrainingUtils import train, kfold_train\n",
    "from Scripts.neuralnets.NNTrainingUtils import train_autoencoder\n",
    "from Scripts.datahandling.BenchmarkDataset import BenchmarkDataset\n",
    "from Scripts.datahandling.Dataloader import Dataloader\n",
    "from Models.Autoencoder import Autoencoder\n",
    "\n",
    "ngpu = 1; device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1632, 'val': 408}\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "batch_size = 128\n",
    "signal_length = 500\n",
=======
    "batch_size = 32\n",
    "signal_length = 1000\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
    "dataset = BenchmarkDataset(Project, signal_length, classes = list(range(1, 5 + 1)))\n",
    "dataloaders, dataset_sizes = Dataloader(dataset, batch_size)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Directly With a CNN"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
=======
   "execution_count": 11,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_initializer():\n",
    "    model_type = 'resnet'; model_size = '18'; num_classes = 40; model_name = model_type + model_size\n",
    "    model = model_selection(model_name, num_classes, pretrained = True)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def optimizer_initializer(model):\n",
    "    return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 12,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 34, 10, 26, 15, 28,  2, 21,  8, 32,  9, 14, 39, 27,  2, 23, 17, 31,\n",
       "        15, 38, 24, 32, 12, 18, 17, 14, 33,  3, 36,  9, 27, 22])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Resnet18 - Pretrained - {} Classes - Adam - {} - Individual {}'.format(5, 500, 1)\n",
    "\n",
    "model, stats = kfold_train(Project, model_initializer, dataset, criterion, optimizer_initializer, num_epochs = 20, num_folds = 5, batch_size = batch_size, log_name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training With Autoencoders\n",
    "\n",
    "Parameters\n",
    "\n",
    "stride - s: \\[1, 2, 4, 8, 16\\]  \n",
    "kernel - k: \\[3, 5, 7, 9, 11\\]  \n",
    "feature_maps - fm: \\[1, 3\\]  "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_initializer(kernel_n, stride, n_feature_maps):\n",
    "    model = Autoencoder(kernel_n = kernel_n, stride = stride, n_feature_maps = n_feature_maps).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
=======
   "execution_count": 31,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
<<<<<<< HEAD
      "            Conv2d-1           [-1, 3, 64, 500]              12\n",
      "              ReLU-2           [-1, 3, 64, 500]               0\n",
      "         MaxPool2d-3  [[-1, 3, 64, 250], [-1, 3, 64, 250]]               0\n",
      "       BatchNorm2d-4           [-1, 3, 64, 250]               6\n",
      "       MaxUnpool2d-5           [-1, 3, 64, 500]               0\n",
      "   ConvTranspose2d-6           [-1, 1, 64, 500]              10\n",
=======
      "         Dropout2d-1          [-1, 1, 64, 1000]               0\n",
      "            Conv2d-2           [-1, 1, 64, 250]               4\n",
      "              ReLU-3           [-1, 1, 64, 250]               0\n",
      "         MaxPool2d-4  [[-1, 1, 64, 125], [-1, 1, 64, 125]]               0\n",
      "       BatchNorm2d-5           [-1, 1, 64, 125]               2\n",
      "       MaxUnpool2d-6           [-1, 1, 64, 250]               0\n",
      "   ConvTranspose2d-7          [-1, 1, 64, 1000]               4\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
      "================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
<<<<<<< HEAD
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 15192.68\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 15192.80\n",
=======
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 486.88\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 487.12\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
<<<<<<< HEAD
    "model = autoencoder_initializer(1, 1, 3)\n",
=======
    "model = autoencoder_initializer(1, 4, 0., 1)\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
    "summary(model, (1, 64, int(signal_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, stats = train_autoencoder(Project, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs = 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(dataloaders['train']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, classifier, encoder):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        self.encoder.eval()\n",
    "#     def normalize(self, X):\n",
    "#         mean = torch.mean(X, dim = 3).unsqueeze(3).expand_as(X)\n",
    "#         std  = torch.std(X, dim = 3).unsqueeze(3).expand_as(X)\n",
    "#         return (X - mean)/std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            x = self.encoder(x)\n",
    "            \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "\n",
    "def hybrid_initializer():\n",
    "    classifier = model_selection(model_name, 5)\n",
    "    classifier.conv1 = nn.Conv2d(3, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    encoder = model.encoder\n",
    "    hybrid = HybridModel(classifier, encoder).to(device)\n",
    "    return hybrid\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_initializer(model):\n",
    "    return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "#     return optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloaders['train']))[0].to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-446fbd874a72>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mhybrid\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhybrid_initializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer_initializer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m30\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\ICDeepLearning\\Scripts\\neuralnets\\NNTrainingUtils.py\u001b[0m in \u001b[0;36mkfold_train\u001b[1;34m(project, model_initializer, dataset, criterion, optimizer_initializer, scheduler_initializer, num_folds, batch_size, save_model, num_epochs, log_name)\u001b[0m\n\u001b[0;32m    210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m         \u001b[0msince\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 212\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    213\u001b[0m         \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msince\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    214\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ICDeepLearning\\Scripts\\neuralnets\\NNTrainingUtils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(project, model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, logger, log_name, kfold)\u001b[0m\n\u001b[0;32m    139\u001b[0m             \u001b[1;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mphase\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "hybrid, stats = kfold_train(Project, hybrid_initializer, dataset, criterion, optimizer_initializer, num_epochs = 30, num_folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Relation(nn.Module):\n",
    "    def __init__(self, weight = None, size_average = None):\n",
    "        super(Relation, self).__init__()\n",
    "        \n",
    "    def forward(self, inputs: torch.tensor) -> torch.float:\n",
    "        return self.function(inputs)\n",
    "    \n",
    "    def function(self, inputs: torch.tensor, *args, **kwargs) -> torch.float:\n",
    "        raise NotImplementedError()\n",
    "        \n",
    "class RelationalLoss(nn.Module):\n",
    "    def __init__(self, loss, relation: Relation, alpha: float = None, weight = None, size_average = None):\n",
    "        super(RelationalLoss, self).__init__()\n",
    "        self.loss = loss\n",
    "        self.relation = relation\n",
    "        self.alpha = alpha\n",
    "        \n",
    "    def forward(self, inputs, targets):\n",
    "        alpha = self.alpha if self.alpha != None else 1\n",
    "        reconstruction = self.loss(inputs, targets)\n",
    "        relation = self.loss(self.relation(inputs), self.relation(targets))\n",
    "        \n",
    "        return (1 - alpha)*reconstruction + alpha*relation, reconstruction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr(X: torch.tensor, Y: torch.tensor = None) -> torch.tensor:\n",
    "    if Y == None:\n",
    "        Y = X\n",
    "        \n",
    "    Mx = X - torch.mean(X, axis = 3).unsqueeze(3)\n",
    "    My = Y - torch.mean(Y, axis = 3).unsqueeze(3)\n",
    "    \n",
    "    n = X.shape[-1]\n",
    "    \n",
    "    Qxy = (1/(n - 1))*torch.matmul(Mx, My.transpose(2, 3))\n",
    "    \n",
    "    return Qxy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
=======
   "execution_count": 21,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, stride, kernel_n, dropout_p, n_feature_maps = 3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        n1 = kernel_n\n",
    "        s = stride\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout2d(dropout_p),\n",
    "            nn.Conv2d(1, n_feature_maps, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s)),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "        self.pool    = nn.MaxPool2d(kernel_size = (1, 2), stride = (1, 2), return_indices = True)\n",
    "        self.batch_norm = nn.BatchNorm2d(n_feature_maps)\n",
    "        self.unpool  = nn.MaxUnpool2d(kernel_size = (1, 2), stride = (1, 2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_feature_maps, 1, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s), output_padding = (0, s - 1))\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x, _2 = self.pool(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.unpool(x, _2)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            x = self.encoder(x)\n",
    "            x, _ = self.pool(x)\n",
    "            x = self.batch_norm(x)\n",
    "            \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 29,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_initializer(kernel_n, stride, dropout_p, n_feature_maps):\n",
    "    model = Autoencoder(kernel_n = kernel_n, stride = stride, dropout_p = dropout_p, n_feature_maps = n_feature_maps).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 15,
=======
   "execution_count": 23,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_initializer():\n",
    "    classifier = model_selection(model_name, 5)\n",
    "    classifier.conv1 = nn.Conv2d(3, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    encoder = model.encoder\n",
    "    hybrid = HybridModel(classifier, encoder).to(device)\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 24,
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_initializer(model):\n",
<<<<<<< HEAD
    "    return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "#     return optim.SGD(model.parameters(), lr = 1e-2, momentum = 0.9)\n",
=======
    "    return optim.SGD(model.classifier.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "#     return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [1]\n",
    "K = [1]\n",
    "FM = [1]\n",
=======
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [2, 4]\n",
    "K = [1]\n",
    "FM = [1, 3]\n",
    "DP = [0]\n",
>>>>>>> 87a592c7a7a5ef9d578ca821581305cd4e03fe43
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "\n",
    "for (s, k, fm, dp) in product(S, K, FM, DP):\n",
    "    # Autoencoder Training\n",
    "    model = Autoencoder(kernel_n = k, stride = s, dropout_p = dp, n_feature_maps = fm).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9, weight_decay = 1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)\n",
    "    name = '1000 - Autoencoder - s = {} k = {} fm = {} dp = {} - 5 classes'.format(s, k, fm, dp)\n",
    "    model, stats = train_autoencoder(Project, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs = 50, log_name = name, scheduler = scheduler)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "        \n",
    "    # Classifier training\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    name = 'ResNet50 - TL - ' + name\n",
    "    hybrid, stats = kfold_train(Project, hybrid_initializer, dataset, criterion, optimizer_initializer, num_epochs = 50, num_folds = 5, log_name = name)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "    \n",
    "    del model\n",
    "    del hybrid\n",
    "    del stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
