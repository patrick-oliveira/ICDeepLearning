{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Project import Project\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torchsummary import summary\n",
    "from itertools import product\n",
    "import pickle\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from Scripts.neuralnets.NNPreinstalledModelSelection import *\n",
    "from Scripts.neuralnets.NNTrainingUtils import train, kfold_train\n",
    "from Scripts.neuralnets.NNTrainingUtils import train_autoencoder\n",
    "from Scripts.datahandling.BenchmarkDataset import BenchmarkDataset\n",
    "from Scripts.datahandling.Dataloader import Dataloader\n",
    "from Models.Autoencoder1 import Autoencoder\n",
    "\n",
    "ngpu = 1; device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 1632, 'val': 408}\n"
     ]
    }
   ],
   "source": [
    "batch_size = 32\n",
    "signal_length = 1000\n",
    "dataset = BenchmarkDataset(Project, signal_length, classes = list(range(1, 5 + 1)))\n",
    "dataloaders, dataset_sizes = Dataloader(dataset, batch_size)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Directly With a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_initializer():\n",
    "    model_type = 'resnet'; model_size = '18'; num_classes = 40; model_name = model_type + model_size\n",
    "    model = model_selection(model_name, num_classes, pretrained = True)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def optimizer_initializer(model):\n",
    "    return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = next(iter(dataloaders['train']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6, 34, 10, 26, 15, 28,  2, 21,  8, 32,  9, 14, 39, 27,  2, 23, 17, 31,\n",
       "        15, 38, 24, 32, 12, 18, 17, 14, 33,  3, 36,  9, 27, 22])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Resnet18 - Pretrained - {} Classes - Adam - {} - Individual {}'.format(5, 500, 1)\n",
    "\n",
    "model, stats = kfold_train(Project, model_initializer, dataset, criterion, optimizer_initializer, num_epochs = 50, num_folds = 5, batch_size = batch_size, log_name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training With Autoencoders\n",
    "\n",
    "Parameters\n",
    "\n",
    "stride - s: \\[1, 2, 4, 8, 16\\]  \n",
    "kernel - k: \\[3, 5, 7, 9, 11\\]  \n",
    "feature_maps - fm: \\[1, 3\\]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "         Dropout2d-1          [-1, 1, 64, 1000]               0\n",
      "            Conv2d-2           [-1, 1, 64, 250]               4\n",
      "              ReLU-3           [-1, 1, 64, 250]               0\n",
      "         MaxPool2d-4  [[-1, 1, 64, 125], [-1, 1, 64, 125]]               0\n",
      "       BatchNorm2d-5           [-1, 1, 64, 125]               2\n",
      "       MaxUnpool2d-6           [-1, 1, 64, 250]               0\n",
      "   ConvTranspose2d-7          [-1, 1, 64, 1000]               4\n",
      "================================================================\n",
      "Total params: 10\n",
      "Trainable params: 10\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.24\n",
      "Forward/backward pass size (MB): 486.88\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 487.12\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = autoencoder_initializer(1, 4, 0., 1)\n",
    "summary(model, (1, 64, int(signal_length)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "# optimizer = optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, stats = train_autoencoder(Project, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = next(iter(dataloaders['train']))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, classifier, encoder):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        self.encoder.eval()\n",
    "#     def normalize(self, X):\n",
    "#         mean = torch.mean(X, dim = 3).unsqueeze(3).expand_as(X)\n",
    "#         std  = torch.std(X, dim = 3).unsqueeze(3).expand_as(X)\n",
    "#         return (X - mean)/std\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "#             x = self.normalize(self.encoder(x))\n",
    "            x = self.encoder(x)\n",
    "            \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "classifier = model_selection(model_name, num_classes)\n",
    "classifier.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "encoder = model.encoder\n",
    "hybrid = HybridModel(classifier, encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(hybrid.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "optimizer = optim. Adam(hy)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid, stats = kfold_train(Project, hybrid, dataset, criterion, optimizer, num_epochs = 10, num_folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, stride, kernel_n, dropout_p, n_feature_maps = 3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        n1 = kernel_n\n",
    "        s = stride\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Dropout2d(dropout_p),\n",
    "            nn.Conv2d(1, n_feature_maps, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s)),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "        self.pool    = nn.MaxPool2d(kernel_size = (1, 2), stride = (1, 2), return_indices = True)\n",
    "        self.batch_norm = nn.BatchNorm2d(n_feature_maps)\n",
    "        self.unpool  = nn.MaxUnpool2d(kernel_size = (1, 2), stride = (1, 2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_feature_maps, 1, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s), output_padding = (0, s - 1))\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x, _2 = self.pool(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.unpool(x, _2)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            x = self.encoder(x)\n",
    "            x, _ = self.pool(x)\n",
    "            x = self.batch_norm(x)\n",
    "            \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_initializer(kernel_n, stride, dropout_p, n_feature_maps):\n",
    "    model = Autoencoder(kernel_n = kernel_n, stride = stride, dropout_p = dropout_p, n_feature_maps = n_feature_maps).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_initializer():\n",
    "    classifier = model_selection(model_name, num_classes)\n",
    "    classifier.conv1 = nn.Conv2d(fm, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    encoder = model.encoder\n",
    "    hybrid = HybridModel(classifier, encoder).to(device)\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_initializer(model):\n",
    "    return optim.SGD(model.classifier.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "#     return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [2, 4]\n",
    "K = [1]\n",
    "FM = [1, 3]\n",
    "DP = [0]\n",
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "\n",
    "for (s, k, fm, dp) in product(S, K, FM, DP):\n",
    "    # Autoencoder Training\n",
    "    model = Autoencoder(kernel_n = k, stride = s, dropout_p = dp, n_feature_maps = fm).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9, weight_decay = 1e-5)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)\n",
    "    name = '1000 - Autoencoder - s = {} k = {} fm = {} dp = {} - 5 classes'.format(s, k, fm, dp)\n",
    "    model, stats = train_autoencoder(Project, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs = 50, log_name = name, scheduler = scheduler)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "        \n",
    "    # Classifier training\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    name = 'ResNet50 - TL - ' + name\n",
    "    hybrid, stats = kfold_train(Project, hybrid_initializer, dataset, criterion, optimizer_initializer, num_epochs = 50, num_folds = 5, log_name = name)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "    \n",
    "    del model\n",
    "    del hybrid\n",
    "    del stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
