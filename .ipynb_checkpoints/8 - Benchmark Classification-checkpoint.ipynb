{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n",
    "from itertools import product\n",
    "import pickle\n",
    "\n",
    "\n",
    "from Scripts.neuralnets.NNPreinstalledModelSelection import *\n",
    "\n",
    "\n",
    "from Scripts.datahandling.BenchmarkDataset import BenchmarkDataset\n",
    "from Scripts.datahandling.Dataloader import Dataloader\n",
    "from Models.Autoencoder1 import Autoencoder\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train': 2448, 'val': 612}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "dataset = BenchmarkDataset(Project, signal_length, classes = list(range(1, 5 + 1)))\n",
    "dataloaders, dataset_sizes = Dataloader(dataset, batch_size)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training Directly With a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_initializer():\n",
    "    model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "    model = model_selection(model_name, num_classes, pretrained = False)\n",
    "    model.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    model = model.to(device)\n",
    "    return model\n",
    "\n",
    "def optimizer_initializer(model):\n",
    "    return optim.Adam(model.parameters(), lr = 1e-3, weight_decay = 1e-5)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "name = 'Resnet18 - Not Pretrained - 2 Classes - Adam'\n",
    "\n",
    "model, stats = kfold_train(Project, model_initializer, dataset, criterion, optimizer_initializer, num_epochs = 50, num_folds = 5, batch_size = batch_size, log_name = name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HybridModel(nn.Module):\n",
    "    def __init__(self, classifier, encoder):\n",
    "        super(HybridModel, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.classifier = classifier\n",
    "        \n",
    "    def forward(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "#             x = self.normalize(self.encoder(x))\n",
    "            x = self.encoder(x)\n",
    "            \n",
    "        x = self.classifier(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "classifier = model_selection(model_name, num_classes)\n",
    "classifier.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "encoder = model.encoder\n",
    "hybrid = HybridModel(classifier, encoder).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# optimizer = optim.SGD(hybrid.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "optimizer = optim. Adam(hy)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)\n",
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hybrid, stats = kfold_train(Project, hybrid, dataset, criterion, optimizer, num_epochs = 10, num_folds = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self, stride, kernel_n, n_feature_maps = 3):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        n1 = kernel_n\n",
    "        s = stride\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, n_feature_maps, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s)),\n",
    "            nn.ReLU(inplace = True),\n",
    "        )\n",
    "        \n",
    "        self.pool    = nn.MaxPool2d(kernel_size = (1, 2), stride = (1, 2), return_indices = True)\n",
    "        self.batch_norm = nn.BatchNorm2d(n_feature_maps)\n",
    "        self.unpool  = nn.MaxUnpool2d(kernel_size = (1, 2), stride = (1, 2))\n",
    "        \n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_feature_maps, 1, kernel_size = (1, 2*n1 + 1), padding = (0, n1), stride = (1, s), output_padding = (0, s - 1))\n",
    "        )\n",
    "        \n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x, _2 = self.pool(x)\n",
    "        x = self.batch_norm(x)\n",
    "        x = self.unpool(x, _2)\n",
    "        x = self.decoder(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def encode(self, x):\n",
    "        with torch.set_grad_enabled(False):\n",
    "            x = self.encoder(x)\n",
    "            x, _ = self.pool(x)\n",
    "            x = self.batch_norm(x)\n",
    "            \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_initializer(kernel_n, stride, n_feature_maps):\n",
    "    model = Autoencoder(kernel_n = kernel_n, stride = stride, n_feature_maps = n_feature_maps).to(device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hybrid_initializer():\n",
    "    classifier = model_selection(model_name, num_classes)\n",
    "    classifier.conv1 = nn.Conv2d(fm, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "    encoder = model.encoder\n",
    "    hybrid = HybridModel(classifier, encoder).to(device)\n",
    "    return hybrid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimizer_initializer(model):\n",
    "    return optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "\n",
    "def scheduler_initializer(optimizer):\n",
    "    return optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S = [1]\n",
    "K = [1, 3, 5]\n",
    "FM = [1, 3]\n",
    "model_type = 'resnet'; model_size = '18'; num_classes = 5; model_name = model_type + model_size\n",
    "\n",
    "for (s, k, fm) in product(S, K, FM):\n",
    "    # Autoencoder Training\n",
    "    model = Autoencoder(kernel_n = k, stride = s, n_feature_maps = fm).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr = 1e-3, momentum = 0.9)\n",
    "    scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.5)\n",
    "    name = 'Autoencoder - s = {} k = {} fm = {} - 5 classes'.format(s, k, fm)\n",
    "    model, stats = train_autoencoder(Project, model, dataloaders, dataset_sizes, criterion, optimizer, num_epochs = 60, log_name = name, scheduler = scheduler)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "        \n",
    "    # Classifier training\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    name = 'ResNet50 - N-TL - ' + name\n",
    "    hybrid, stats = kfold_train(Project, hybrid_initializer, dataset, criterion, optimizer_initializer, num_epochs = 30, num_folds = 5, log_name = name)\n",
    "    \n",
    "    with open('Outputs/'+name+' - stats', 'wb') as stats_file:\n",
    "        pickle.dump(stats, stats_file)\n",
    "    \n",
    "    del model\n",
    "    del hybrid\n",
    "    del stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
