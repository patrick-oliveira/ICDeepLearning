{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Project import Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from Scripts.data.DataLoading import get_image_dataloaders, get_image_dataset\n",
    "from Scripts.data.SSVEPDataset import SSVEPDataset\n",
    "from Scripts.data.SSVEPDataloader import SSVEPDataloader\n",
    "from Scripts.neuralnets.NNPreinstalledModelSelection import *\n",
    "from Scripts.neuralnets.NNTrainingUtils import train, kfold_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ngpu = 1; device = torch.device(\"cuda:0\" if (torch.cuda.is_available() and ngpu > 0) else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with simple cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = 'cca'\n",
    "signal_length = '512'\n",
    "fig_type = 'rp'\n",
    "dataloaders, dataset_sizes = get_image_dataloaders(Project, preprocessing, signal_length, fig_type, batch_size = 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '50'; num_classes = 5; model_name = model_type + model_size\n",
    "model = model_selection(model_name, num_classes, pretrained = False).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 10, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, stats = train(Project, model, dataloaders, dataset_sizes, criterion, optimizer, scheduler, num_epochs = 15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with K-Fold cross validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = 'cca'\n",
    "signal_length = '1280'\n",
    "fig_type = 'rp'\n",
    "dataset = get_image_dataset(Project, preprocessing, signal_length, fig_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '50'; num_classes = 5; model_name = model_type + model_size\n",
    "model = model_selection(model_name, num_classes).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.4)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 5, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23/Sep/2020 14:45:42] INFO - Fold 0\n",
      "[23/Sep/2020 14:45:42] INFO - Epoch    Stage       Loss    Accuracy\n",
      "\n",
      "[23/Sep/2020 14:46:40] INFO - 1/20     Training    1.65    0.21    \n",
      "[23/Sep/2020 14:46:45] INFO -          Validation  1.69    0.19    \n",
      "[23/Sep/2020 14:47:41] INFO - 2/20     Training    1.58    0.27    \n",
      "[23/Sep/2020 14:47:45] INFO -          Validation  1.61    0.24    \n",
      "[23/Sep/2020 14:48:38] INFO - 3/20     Training    1.54    0.30    \n",
      "[23/Sep/2020 14:48:42] INFO -          Validation  1.62    0.24    \n",
      "[23/Sep/2020 14:49:40] INFO - 4/20     Training    1.44    0.39    \n",
      "[23/Sep/2020 14:49:44] INFO -          Validation  1.73    0.25    \n",
      "[23/Sep/2020 14:50:39] INFO - 5/20     Training    1.33    0.46    \n",
      "[23/Sep/2020 14:50:43] INFO -          Validation  1.76    0.24    \n",
      "[23/Sep/2020 14:51:37] INFO - 6/20     Training    1.12    0.58    \n",
      "[23/Sep/2020 14:51:41] INFO -          Validation  1.87    0.24    \n",
      "[23/Sep/2020 14:52:40] INFO - 7/20     Training    0.89    0.68    \n",
      "[23/Sep/2020 14:52:44] INFO -          Validation  1.98    0.30    \n",
      "[23/Sep/2020 14:53:42] INFO - 8/20     Training    0.70    0.78    \n",
      "[23/Sep/2020 14:53:47] INFO -          Validation  2.21    0.31    \n",
      "[23/Sep/2020 14:54:46] INFO - 9/20     Training    0.51    0.85    \n",
      "[23/Sep/2020 14:54:51] INFO -          Validation  2.43    0.27    \n",
      "[23/Sep/2020 14:55:49] INFO - 10/20    Training    0.46    0.84    \n",
      "[23/Sep/2020 14:55:53] INFO -          Validation  2.76    0.23    \n",
      "[23/Sep/2020 14:56:53] INFO - 11/20    Training    0.37    0.88    \n",
      "[23/Sep/2020 14:56:58] INFO -          Validation  2.80    0.26    \n",
      "[23/Sep/2020 14:58:01] INFO - 12/20    Training    0.37    0.88    \n",
      "[23/Sep/2020 14:58:05] INFO -          Validation  2.85    0.22    \n",
      "[23/Sep/2020 14:59:03] INFO - 13/20    Training    0.33    0.89    \n",
      "[23/Sep/2020 14:59:07] INFO -          Validation  3.11    0.24    \n",
      "[23/Sep/2020 15:00:04] INFO - 14/20    Training    0.31    0.89    \n",
      "[23/Sep/2020 15:00:08] INFO -          Validation  3.07    0.19    \n",
      "[23/Sep/2020 15:01:11] INFO - 15/20    Training    0.27    0.91    \n",
      "[23/Sep/2020 15:01:17] INFO -          Validation  3.20    0.23    \n",
      "[23/Sep/2020 15:02:17] INFO - 16/20    Training    0.25    0.91    \n",
      "[23/Sep/2020 15:02:22] INFO -          Validation  3.51    0.22    \n",
      "[23/Sep/2020 15:03:20] INFO - 17/20    Training    0.29    0.90    \n",
      "[23/Sep/2020 15:03:24] INFO -          Validation  3.17    0.24    \n",
      "[23/Sep/2020 15:04:21] INFO - 18/20    Training    0.29    0.89    \n",
      "[23/Sep/2020 15:04:26] INFO -          Validation  3.18    0.27    \n",
      "[23/Sep/2020 15:05:33] INFO - 19/20    Training    0.26    0.92    \n",
      "[23/Sep/2020 15:05:38] INFO -          Validation  3.16    0.20    \n",
      "[23/Sep/2020 15:06:41] INFO - 20/20    Training    0.22    0.93    \n",
      "[23/Sep/2020 15:06:46] INFO -          Validation  3.38    0.26    \n",
      "[23/Sep/2020 15:06:46] INFO - Training complete in 21m 3s\n",
      "[23/Sep/2020 15:06:46] INFO - Best Validation Accuracy: 0.31\n",
      "[23/Sep/2020 15:06:46] INFO - Best Validation Loss: 2.21\n",
      "\n",
      "[23/Sep/2020 15:06:46] INFO - Fold 1\n",
      "[23/Sep/2020 15:06:46] INFO - Epoch    Stage       Loss    Accuracy\n",
      "\n",
      "[23/Sep/2020 15:07:43] INFO - 1/20     Training    1.65    0.22    \n",
      "[23/Sep/2020 15:07:47] INFO -          Validation  1.65    0.22    \n",
      "[23/Sep/2020 15:08:47] INFO - 2/20     Training    1.60    0.27    \n",
      "[23/Sep/2020 15:08:53] INFO -          Validation  1.68    0.17    \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-bdaa4a68e9c8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkfold_train\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mProject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m20\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_folds\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m7\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Documents\\GitHub\\ICDeepLearning\\Scripts\\neuralnets\\NNTrainingUtils.py\u001b[0m in \u001b[0;36mkfold_train\u001b[1;34m(project, model, dataset, criterion, optimizer, scheduler, num_folds, batch_size, save_model, num_epochs)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m         \u001b[0msince\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataloaders\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdataset_size\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscheduler\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogger\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlogger\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkfold\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m         \u001b[0mtime_elapsed\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msince\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Documents\\GitHub\\ICDeepLearning\\Scripts\\neuralnets\\NNTrainingUtils.py\u001b[0m in \u001b[0;36mtrain\u001b[1;34m(project, model, dataloaders, dataset_size, criterion, optimizer, scheduler, num_epochs, logger, kfold)\u001b[0m\n\u001b[0;32m    134\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    135\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 136\u001b[1;33m                 \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    137\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mset_grad_enabled\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mphase\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'train'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    138\u001b[0m                     \u001b[0moutputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\torch\\optim\\optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    163\u001b[0m                 \u001b[1;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    164\u001b[0m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdetach_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 165\u001b[1;33m                     \u001b[0mp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclosure\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model, stats = kfold_train(Project, model, dataset, criterion, optimizer, num_epochs = 20, num_folds = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training with K-Fold cross validation and data preprocessed uniquely with CCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocessing = 'cca'\n",
    "signal_length = '512'\n",
    "data = pd.read_csv((Project.output_dir / ('SSVEPDataset_'+signal_length+'.csv')).__str__(), dtype = 'str')\n",
    "dataset = SSVEPDataset(Project, preprocessing, data, signal_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "dataloaders, dataset_sizes = SSVEPDataloader(dataset, batch_size)\n",
    "print(dataset_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_type = 'resnet'; model_size = '50'; num_classes = 5; model_name = model_type + model_size\n",
    "model = model_selection(model_name, num_classes)\n",
    "model.conv1 = nn.Conv2d(1, 64, kernel_size = (7, 7), stride = (2, 2), padding = (3, 3), bias = False)\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum = 0.9)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size = 7, gamma = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model, stats = kfold_train(Project, model, dataset, criterion, optimizer, num_epochs = 20, num_folds = 5)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
