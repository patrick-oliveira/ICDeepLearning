{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "from Scripts.Components import *\n",
    "from typing import Tuple\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "sample_input = torch.rand((16, 1, 64, 500))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchsummary import summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Advantages of depthwise convolutions: less parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleSepDepthAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, n_filters:int, kernel_size:int, depth:int):\n",
    "        assert kernel_size % 2 != 0, 'kernel_size must be an odd number in order to auto padding to work'\n",
    "        separable_convolution = SeparableConv2D(1, n_filters, kernel_size = (64, kernel_size), padding = (0, kernel_size//2))\n",
    "        depthwise_convolution = DepthwiseConv2D(n_filters, depth*n_filters, kernel_size = (1, 5), padding = (0, 5//2), stride = (1, 2))\n",
    "        \n",
    "        return nn.Sequential(separable_convolution,\n",
    "                             depthwise_convolution,\n",
    "                             Transpose_1_2())\n",
    "        \n",
    "    def build_decoder(self, n_filters:int, kernel_size:int, depth:int):\n",
    "        depthwise_deconvolution = nn.ConvTranspose2d(depth*n_filters, n_filters, kernel_size = (1, 5), padding = (0, 5//2), stride = (1, 2), output_padding = (0, 1))\n",
    "        separable_deconvolution = SeparableDeconv2D(n_filters, 1, kernel_size = (64, kernel_size), padding = (0, kernel_size//2))\n",
    "        \n",
    "        return nn.Sequential(Transpose_1_2(),\n",
    "                             depthwise_deconvolution,\n",
    "                             separable_deconvolution)\n",
    "    \n",
    "    \n",
    "class Transpose_1_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transpose_1_2, self).__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = SimpleSepDepthAutoencoder(n_filters = 1, kernel_size = 25, depth = 250)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 1, 64, 476]              25\n",
      "            Conv2d-2            [-1, 1, 1, 500]              64\n",
      "   SeparableConv2D-3            [-1, 1, 1, 500]               0\n",
      "            Conv2d-4          [-1, 250, 1, 250]           1,250\n",
      "   DepthwiseConv2D-5          [-1, 250, 1, 250]               0\n",
      "     Transpose_1_2-6          [-1, 1, 250, 250]               0\n",
      "     Transpose_1_2-7          [-1, 250, 1, 250]               0\n",
      "   ConvTranspose2d-8            [-1, 1, 1, 500]           1,251\n",
      "   ConvTranspose2d-9           [-1, 1, 64, 476]              65\n",
      "  ConvTranspose2d-10           [-1, 1, 64, 500]              26\n",
      "SeparableDeconv2D-11           [-1, 1, 64, 500]               0\n",
      "================================================================\n",
      "Total params: 2,681\n",
      "Trainable params: 2,681\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 2.87\n",
      "Params size (MB): 0.01\n",
      "Estimated Total Size (MB): 3.00\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PicSepDepthAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, n_filters:int, kernel_size:int):\n",
    "        assert kernel_size % 2 != 0, 'kernel_size must be an odd number in order to auto padding to work'\n",
    "        \n",
    "        separable_convolution = SeparableConv2D(1, n_filters, kernel_size = (64, kernel_size), padding = (0, kernel_size // 2), stride = (1, 1))\n",
    "        conv_size_reduction = nn.Sequential(\n",
    "            nn.Conv2d(n_filters, n_filters, kernel_size = (1, 5), padding = (0, 2), stride = (1, 2)),\n",
    "            nn.Conv2d(n_filters, n_filters, kernel_size = (1, 5), padding = (0, 2), stride = (1, 2))\n",
    "        )\n",
    "        make_pic = Transpose_1_2()        \n",
    "            \n",
    "        return nn.Sequential(separable_convolution,\n",
    "                             conv_size_reduction,\n",
    "                             make_pic)\n",
    "        \n",
    "    def build_decoder(self, n_filters:int, kernel_size:int):\n",
    "        unmake_pic = Transpose_1_2()\n",
    "        conv_size_increase = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_filters, n_filters, kernel_size = (1, 5), padding = (0, 2), stride = (1, 2), output_padding = (0, 1)),\n",
    "            nn.ConvTranspose2d(n_filters, n_filters, kernel_size = (1, 5), padding = (0, 2), stride = (1, 2), output_padding = (0, 1))\n",
    "        )\n",
    "        separable_deconvolution = SeparableDeconv2D(n_filters, 1, kernel_size = (64, kernel_size), padding = (0, kernel_size//2), stride = (1, 1))\n",
    "        \n",
    "        return nn.Sequential(unmake_pic,\n",
    "                             conv_size_increase,\n",
    "                             separable_deconvolution)\n",
    "    \n",
    "class Transpose_1_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transpose_1_2, self).__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 125, 64, 476]           3,125\n",
      "            Conv2d-2          [-1, 125, 1, 500]       1,000,000\n",
      "   SeparableConv2D-3          [-1, 125, 1, 500]               0\n",
      "            Conv2d-4          [-1, 125, 1, 250]          78,250\n",
      "            Conv2d-5          [-1, 125, 1, 125]          78,250\n",
      "     Transpose_1_2-6          [-1, 1, 125, 125]               0\n",
      "     Transpose_1_2-7          [-1, 125, 1, 125]               0\n",
      "   ConvTranspose2d-8          [-1, 125, 1, 250]          78,250\n",
      "   ConvTranspose2d-9          [-1, 125, 1, 500]          78,250\n",
      "  ConvTranspose2d-10         [-1, 125, 64, 476]       1,000,125\n",
      "  ConvTranspose2d-11           [-1, 1, 64, 500]           3,126\n",
      "SeparableDeconv2D-12           [-1, 1, 64, 500]               0\n",
      "================================================================\n",
      "Total params: 2,319,376\n",
      "Trainable params: 2,319,376\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 60.86\n",
      "Params size (MB): 8.85\n",
      "Estimated Total Size (MB): 69.83\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder = PicSepDepthAutoencoder(n_filters = 125, kernel_size = 25)\n",
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, n_filters:int, kernel_size:int, stride:int):\n",
    "        assert kernel_size %2 != 0, 'kernel_size must be an odd number in order to auto padding to work'\n",
    "        encoder = nn.Sequential(\n",
    "            nn.Conv2d(1, n_filters, kernel_size = (1, kernel_size), padding = (0, kernel_size//2), stride = (1, stride)),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Conv2d(n_filters, n_filters, kernel_size = (1, 3), padding = (0, 1), stride = (1, 2))\n",
    "        )\n",
    "        \n",
    "        return encoder\n",
    "        \n",
    "    def build_decoder(self, n_filters:int, kernel_size:int, stride:int):\n",
    "        assert kernel_size %2 != 0, 'kernel_size must be an odd number in order to auto padding to work'\n",
    "        decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(n_filters, n_filters, kernel_size = (1, 3), padding = (0, 1), stride = (1, 2), output_padding = (0, 1)),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.BatchNorm2d(n_filters),\n",
    "            nn.ConvTranspose2d(n_filters, 1, kernel_size = (1, kernel_size), padding = (0, kernel_size//2), stride = (1, stride), output_padding = (0, stride - 1)),\n",
    "        )\n",
    "        \n",
    "        return decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 1, 64, 250]               6\n",
      "       BatchNorm2d-2           [-1, 1, 64, 250]               2\n",
      "              ReLU-3           [-1, 1, 64, 250]               0\n",
      "            Conv2d-4           [-1, 1, 64, 125]               4\n",
      "   ConvTranspose2d-5           [-1, 1, 64, 250]               4\n",
      "              ReLU-6           [-1, 1, 64, 250]               0\n",
      "       BatchNorm2d-7           [-1, 1, 64, 250]               2\n",
      "   ConvTranspose2d-8           [-1, 1, 64, 500]               6\n",
      "================================================================\n",
      "Total params: 24\n",
      "Trainable params: 24\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 1.04\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 1.16\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder = SimpleAutoencoder(n_filters = 1, kernel_size = 5, stride = 2)\n",
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SepConvAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, n_filters, kernel_size):\n",
    "        first_conv = nn.Conv2d(1, n_filters, kernel_size = (1, kernel_size), padding = (0, kernel_size//2))\n",
    "        separable_convolution = SeparableConv2D(n_filters, n_filters, kernel_size = (64, kernel_size), padding = (0, kernel_size//2), stride = (1, 2))\n",
    "        \n",
    "        return nn.Sequential(first_conv,\n",
    "                             separable_convolution)\n",
    "    \n",
    "    def build_decoder(self, n_filters, kernel_size):\n",
    "        separable_deconvolution = SeparableDeconv2D(n_filters, n_filters, kernel_size = (64, kernel_size), padding = (0, kernel_size//2), stride = (1, 2))\n",
    "        deconv = nn.ConvTranspose2d(n_filters, 1, kernel_size = (1, kernel_size), padding = (0, kernel_size//2))\n",
    "        \n",
    "        return nn.Sequential(separable_deconvolution,\n",
    "                             deconv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 64, 500]             384\n",
      "            Conv2d-2          [-1, 64, 64, 250]             320\n",
      "            Conv2d-3           [-1, 64, 1, 250]           4,096\n",
      "   SeparableConv2D-4           [-1, 64, 1, 250]               0\n",
      "   ConvTranspose2d-5          [-1, 64, 64, 250]           4,160\n",
      "   ConvTranspose2d-6          [-1, 64, 64, 500]          20,544\n",
      " SeparableDeconv2D-7          [-1, 64, 64, 500]               0\n",
      "   ConvTranspose2d-8           [-1, 1, 64, 500]             321\n",
      "================================================================\n",
      "Total params: 29,825\n",
      "Trainable params: 29,825\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 62.99\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 63.22\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder = SepConvAutoencoder(n_filters = 64, kernel_size = 5)\n",
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input: (B, C, 1, T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class mAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, depth:int, kernel_size, n_filters: int):\n",
    "        sep_conv = SeparableConv2D(1, n_filters, kernel_size = (64, kernel_size), padding =  (0, kernel_size//2))\n",
    "        # High-level feature maps, time compression\n",
    "        high_level_features = DepthwiseSeparableConv2D(n_filters, depth * n_filters, depth = depth, kernel_size = (1, kernel_size), padding = (0, kernel_size//2),\n",
    "                                                       stride = (1, 2))\n",
    "        # Pic Encoding\n",
    "        pic_encoding = Transpose_1_2()\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            sep_conv,\n",
    "            high_level_features,\n",
    "            pic_encoding,\n",
    "        )\n",
    "    \n",
    "    def build_decoder(self, depth:int, kernel_size:int, n_filters:int):\n",
    "        # Pic Decoding\n",
    "        pic_decoding = Transpose_1_2()\n",
    "        # Info reconstruction (really necessary?)\n",
    "        high_level_features_decoding = DepthwiseSeparableDeconv2D(depth * n_filters, n_filters, kernel_size = (1, kernel_size), padding = (0, kernel_size // 2),\n",
    "                                                                  stride = (1, 2))\n",
    "        sep_deconv = SeparableDeconv2D(n_filters, 1, kernel_size = (64, kernel_size), padding = (0, kernel_size//2))\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            pic_decoding,\n",
    "            high_level_features_decoding,\n",
    "            sep_deconv,\n",
    "        )\n",
    "    \n",
    "class Transpose_1_2(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Transpose_1_2, self).__init__()\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return X.transpose(1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 64, 64, 500]             320\n",
      "            Conv2d-2           [-1, 64, 1, 500]           4,096\n",
      "   SeparableConv2D-3           [-1, 64, 1, 500]               0\n",
      "            Conv2d-4           [-1, 64, 1, 250]             320\n",
      "            Conv2d-5           [-1, 64, 1, 250]           4,096\n",
      "DepthwiseSeparableConv2D-6           [-1, 64, 1, 250]               0\n",
      "     Transpose_1_2-7           [-1, 1, 64, 250]               0\n",
      "     Transpose_1_2-8           [-1, 64, 1, 250]               0\n",
      "            Conv2d-9           [-1, 64, 1, 250]           4,096\n",
      "  ConvTranspose2d-10           [-1, 64, 1, 500]             320\n",
      "DepthwiseSeparableDeconv2D-11           [-1, 64, 1, 500]               0\n",
      "  ConvTranspose2d-12          [-1, 64, 64, 500]           4,160\n",
      "  ConvTranspose2d-13           [-1, 1, 64, 500]             321\n",
      "SeparableDeconv2D-14           [-1, 1, 64, 500]               0\n",
      "================================================================\n",
      "Total params: 17,729\n",
      "Trainable params: 17,729\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 33.45\n",
      "Params size (MB): 0.07\n",
      "Estimated Total Size (MB): 33.64\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder = mAutoencoder(depth = 1, kernel_size = 5, n_filters = 64)\n",
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MiddleFlow(nn.Module):\n",
    "    def __init__(self, num_maps, kernel_size):\n",
    "        super(MiddleFlow, self).__init__()\n",
    "        self.flow = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableConv2D(num_maps, num_maps, kernel_size, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableConv2D(num_maps, num_maps, kernel_size, padding = 1),\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableConv2D(num_maps, num_maps, kernel_size, padding = 1)\n",
    "        )\n",
    "    \n",
    "    def forward(self, X):\n",
    "        return X + self.flow(X)\n",
    "    \n",
    "class ResidualDepthwiseSepBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualDepthwiseSepBlock, self).__init__()\n",
    "        self.flow = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableConv2D(in_channels, out_channels, (1, 3), padding = (0, 1)),\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableConv2D(out_channels, out_channels, (1, 3), padding = (0, 1)),\n",
    "            nn.Conv2d(out_channels, out_channels, (1, 3), stride = (1, 2), padding = (0, 1), groups = out_channels)\n",
    "        )\n",
    "        self.residue = nn.Conv2d(in_channels, out_channels, kernel_size = 1, stride = (1, 2))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.flow(X) + self.residue(X)\n",
    "    \n",
    "class ResidualDepthwiseSepDeconvBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(ResidualDepthwiseSepDeconvBlock, self).__init__()\n",
    "        self.flow = nn.Sequential(\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableDeconv2D(in_channels, out_channels, kernel_size = (1, 3), padding = (0, 1)),\n",
    "            nn.ReLU(),\n",
    "            DepthwiseSeparableDeconv2D(out_channels, out_channels, kernel_size = (1, 3), padding = (0, 1)),\n",
    "            nn.ConvTranspose2d(out_channels, out_channels, (1, 3), stride = (1, 2), padding = (0, 1), output_padding = (0, 1), groups = out_channels)\n",
    "        )\n",
    "        self.residue = nn.ConvTranspose2d(in_channels, out_channels, kernel_size = 1, stride = (1, 2), output_padding = (0, 1))\n",
    "        \n",
    "    def forward(self, X):\n",
    "        return self.flow(X) + self.residue(X)\n",
    "    \n",
    "class DeepXAutoencoder(Autoencoder):\n",
    "    def build_encoder(self, depth:int, kernel_size, n_filters: int):\n",
    "        # Temporal processing\n",
    "        temporal_filters = nn.Conv2d(1, n_filters, kernel_size = (1, kernel_size), padding = (0, kernel_size//2))\n",
    "        high_level_features = ResidualDepthwiseSepBlock(n_filters, depth*n_filters)\n",
    "        # Spatial processing, spatial compression\n",
    "        spatial_filter   = nn.Conv2d(depth * n_filters, depth * n_filters, kernel_size = (64, 1), padding = (0, 0)) # [n_filters, 1, T]\n",
    "        # Pic Encoding\n",
    "        pic_encoding = Transpose_1_2()\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            temporal_filters,\n",
    "            high_level_features,\n",
    "            spatial_filter,\n",
    "            pic_encoding,\n",
    "        )\n",
    "    \n",
    "    def build_decoder(self, depth:int, kernel_size, n_filters: int):\n",
    "        # Pic Decoding\n",
    "        pic_decoding = Transpose_1_2()\n",
    "        # Spatial reconstruction\n",
    "        spatial_reconstruction = nn.ConvTranspose2d(depth * n_filters, depth * n_filters, kernel_size = (64, 1), padding = (0, 0))\n",
    "        # Info reconstruction (really necessary?)\n",
    "        high_level_features_decoding = ResidualDepthwiseSepDeconvBlock(depth * n_filters, n_filters)\n",
    "        # Temporal reconstruction\n",
    "        temporal_reconstruction = nn.ConvTranspose2d(n_filters, 1, kernel_size = (1, kernel_size), padding = (0, kernel_size//2))\n",
    "        \n",
    "        return nn.Sequential(\n",
    "            pic_decoding,\n",
    "            spatial_reconstruction,\n",
    "            high_level_features_decoding,\n",
    "            temporal_reconstruction,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1          [-1, 16, 64, 500]              96\n",
      "              ReLU-2          [-1, 16, 64, 500]               0\n",
      "            Conv2d-3          [-1, 16, 64, 500]              48\n",
      "            Conv2d-4          [-1, 16, 64, 500]             256\n",
      "DepthwiseSeparableConv2D-5          [-1, 16, 64, 500]               0\n",
      "              ReLU-6          [-1, 16, 64, 500]               0\n",
      "            Conv2d-7          [-1, 16, 64, 500]              48\n",
      "            Conv2d-8          [-1, 16, 64, 500]             256\n",
      "DepthwiseSeparableConv2D-9          [-1, 16, 64, 500]               0\n",
      "           Conv2d-10          [-1, 16, 64, 250]              64\n",
      "           Conv2d-11          [-1, 16, 64, 250]             272\n",
      "ResidualDepthwiseSepBlock-12          [-1, 16, 64, 250]               0\n",
      "           Conv2d-13           [-1, 16, 1, 250]          16,400\n",
      "    Transpose_1_2-14           [-1, 1, 16, 250]               0\n",
      "    Transpose_1_2-15           [-1, 16, 1, 250]               0\n",
      "  ConvTranspose2d-16          [-1, 16, 64, 250]          16,400\n",
      "             ReLU-17          [-1, 16, 64, 250]               0\n",
      "           Conv2d-18          [-1, 16, 64, 250]             256\n",
      "  ConvTranspose2d-19          [-1, 16, 64, 250]              48\n",
      "DepthwiseSeparableDeconv2D-20          [-1, 16, 64, 250]               0\n",
      "             ReLU-21          [-1, 16, 64, 250]               0\n",
      "           Conv2d-22          [-1, 16, 64, 250]             256\n",
      "  ConvTranspose2d-23          [-1, 16, 64, 250]              48\n",
      "DepthwiseSeparableDeconv2D-24          [-1, 16, 64, 250]               0\n",
      "  ConvTranspose2d-25          [-1, 16, 64, 500]              64\n",
      "  ConvTranspose2d-26          [-1, 16, 64, 500]             272\n",
      "ResidualDepthwiseSepDeconvBlock-27          [-1, 16, 64, 500]               0\n",
      "  ConvTranspose2d-28           [-1, 1, 64, 500]              81\n",
      "================================================================\n",
      "Total params: 34,865\n",
      "Trainable params: 34,865\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.12\n",
      "Forward/backward pass size (MB): 70.65\n",
      "Params size (MB): 0.13\n",
      "Estimated Total Size (MB): 70.90\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "autoencoder = DeepXAutoencoder(depth = 1, kernel_size = 5, n_filters = 16)\n",
    "summary(autoencoder, (1, 64, 500), device = 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
